// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/config.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "tensorflow/core/protobuf/config.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {

namespace {

const ::google::protobuf::Descriptor* GPUOptions_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  GPUOptions_reflection_ = NULL;
const ::google::protobuf::Descriptor* OptimizerOptions_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  OptimizerOptions_reflection_ = NULL;
const ::google::protobuf::EnumDescriptor* OptimizerOptions_Level_descriptor_ = NULL;
const ::google::protobuf::Descriptor* GraphOptions_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  GraphOptions_reflection_ = NULL;
const ::google::protobuf::Descriptor* ThreadPoolOptionProto_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ThreadPoolOptionProto_reflection_ = NULL;
const ::google::protobuf::Descriptor* ConfigProto_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  ConfigProto_reflection_ = NULL;
const ::google::protobuf::Descriptor* ConfigProto_DeviceCountEntry_descriptor_ = NULL;
const ::google::protobuf::Descriptor* DebugTensorWatch_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  DebugTensorWatch_reflection_ = NULL;
const ::google::protobuf::Descriptor* RunOptions_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  RunOptions_reflection_ = NULL;
const ::google::protobuf::EnumDescriptor* RunOptions_TraceLevel_descriptor_ = NULL;
const ::google::protobuf::Descriptor* RunMetadata_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  RunMetadata_reflection_ = NULL;

}  // namespace


void protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto() {
  protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto();
  const ::google::protobuf::FileDescriptor* file =
    ::google::protobuf::DescriptorPool::generated_pool()->FindFileByName(
      "tensorflow/core/protobuf/config.proto");
  GOOGLE_CHECK(file != NULL);
  GPUOptions_descriptor_ = file->message_type(0);
  static const int GPUOptions_offsets_[4] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GPUOptions, per_process_gpu_memory_fraction_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GPUOptions, allocator_type_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GPUOptions, deferred_deletion_bytes_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GPUOptions, allow_growth_),
  };
  GPUOptions_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      GPUOptions_descriptor_,
      GPUOptions::default_instance_,
      GPUOptions_offsets_,
      -1,
      -1,
      -1,
      sizeof(GPUOptions),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GPUOptions, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GPUOptions, _is_default_instance_));
  OptimizerOptions_descriptor_ = file->message_type(1);
  static const int OptimizerOptions_offsets_[4] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(OptimizerOptions, do_common_subexpression_elimination_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(OptimizerOptions, do_constant_folding_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(OptimizerOptions, do_function_inlining_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(OptimizerOptions, opt_level_),
  };
  OptimizerOptions_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      OptimizerOptions_descriptor_,
      OptimizerOptions::default_instance_,
      OptimizerOptions_offsets_,
      -1,
      -1,
      -1,
      sizeof(OptimizerOptions),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(OptimizerOptions, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(OptimizerOptions, _is_default_instance_));
  OptimizerOptions_Level_descriptor_ = OptimizerOptions_descriptor_->enum_type(0);
  GraphOptions_descriptor_ = file->message_type(2);
  static const int GraphOptions_offsets_[5] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GraphOptions, enable_recv_scheduling_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GraphOptions, optimizer_options_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GraphOptions, build_cost_model_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GraphOptions, infer_shapes_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GraphOptions, place_pruned_graph_),
  };
  GraphOptions_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      GraphOptions_descriptor_,
      GraphOptions::default_instance_,
      GraphOptions_offsets_,
      -1,
      -1,
      -1,
      sizeof(GraphOptions),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GraphOptions, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(GraphOptions, _is_default_instance_));
  ThreadPoolOptionProto_descriptor_ = file->message_type(3);
  static const int ThreadPoolOptionProto_offsets_[1] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ThreadPoolOptionProto, num_threads_),
  };
  ThreadPoolOptionProto_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ThreadPoolOptionProto_descriptor_,
      ThreadPoolOptionProto::default_instance_,
      ThreadPoolOptionProto_offsets_,
      -1,
      -1,
      -1,
      sizeof(ThreadPoolOptionProto),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ThreadPoolOptionProto, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ThreadPoolOptionProto, _is_default_instance_));
  ConfigProto_descriptor_ = file->message_type(4);
  static const int ConfigProto_offsets_[12] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, device_count_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, intra_op_parallelism_threads_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, inter_op_parallelism_threads_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, use_per_session_threads_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, session_inter_op_thread_pool_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, placement_period_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, device_filters_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, gpu_options_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, allow_soft_placement_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, log_device_placement_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, graph_options_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, operation_timeout_in_ms_),
  };
  ConfigProto_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      ConfigProto_descriptor_,
      ConfigProto::default_instance_,
      ConfigProto_offsets_,
      -1,
      -1,
      -1,
      sizeof(ConfigProto),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ConfigProto, _is_default_instance_));
  ConfigProto_DeviceCountEntry_descriptor_ = ConfigProto_descriptor_->nested_type(0);
  DebugTensorWatch_descriptor_ = file->message_type(5);
  static const int DebugTensorWatch_offsets_[4] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(DebugTensorWatch, node_name_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(DebugTensorWatch, output_slot_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(DebugTensorWatch, debug_ops_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(DebugTensorWatch, debug_urls_),
  };
  DebugTensorWatch_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      DebugTensorWatch_descriptor_,
      DebugTensorWatch::default_instance_,
      DebugTensorWatch_offsets_,
      -1,
      -1,
      -1,
      sizeof(DebugTensorWatch),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(DebugTensorWatch, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(DebugTensorWatch, _is_default_instance_));
  RunOptions_descriptor_ = file->message_type(6);
  static const int RunOptions_offsets_[4] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunOptions, trace_level_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunOptions, timeout_in_ms_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunOptions, inter_op_thread_pool_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunOptions, debug_tensor_watch_opts_),
  };
  RunOptions_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      RunOptions_descriptor_,
      RunOptions::default_instance_,
      RunOptions_offsets_,
      -1,
      -1,
      -1,
      sizeof(RunOptions),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunOptions, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunOptions, _is_default_instance_));
  RunOptions_TraceLevel_descriptor_ = RunOptions_descriptor_->enum_type(0);
  RunMetadata_descriptor_ = file->message_type(7);
  static const int RunMetadata_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunMetadata, step_stats_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunMetadata, cost_graph_),
  };
  RunMetadata_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      RunMetadata_descriptor_,
      RunMetadata::default_instance_,
      RunMetadata_offsets_,
      -1,
      -1,
      -1,
      sizeof(RunMetadata),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunMetadata, _internal_metadata_),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RunMetadata, _is_default_instance_));
}

namespace {

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AssignDescriptors_once_);
inline void protobuf_AssignDescriptorsOnce() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AssignDescriptors_once_,
                 &protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto);
}

void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      GPUOptions_descriptor_, &GPUOptions::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      OptimizerOptions_descriptor_, &OptimizerOptions::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      GraphOptions_descriptor_, &GraphOptions::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ThreadPoolOptionProto_descriptor_, &ThreadPoolOptionProto::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      ConfigProto_descriptor_, &ConfigProto::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
        ConfigProto_DeviceCountEntry_descriptor_,
        ::google::protobuf::internal::MapEntry<
            ::std::string,
            ::google::protobuf::int32,
            ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
            ::google::protobuf::internal::WireFormatLite::TYPE_INT32,
            0>::CreateDefaultInstance(
                ConfigProto_DeviceCountEntry_descriptor_));
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      DebugTensorWatch_descriptor_, &DebugTensorWatch::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      RunOptions_descriptor_, &RunOptions::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      RunMetadata_descriptor_, &RunMetadata::default_instance());
}

}  // namespace

void protobuf_ShutdownFile_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto() {
  delete GPUOptions::default_instance_;
  delete GPUOptions_reflection_;
  delete OptimizerOptions::default_instance_;
  delete OptimizerOptions_reflection_;
  delete GraphOptions::default_instance_;
  delete GraphOptions_reflection_;
  delete ThreadPoolOptionProto::default_instance_;
  delete ThreadPoolOptionProto_reflection_;
  delete ConfigProto::default_instance_;
  delete ConfigProto_reflection_;
  delete DebugTensorWatch::default_instance_;
  delete DebugTensorWatch_reflection_;
  delete RunOptions::default_instance_;
  delete RunOptions_reflection_;
  delete RunMetadata::default_instance_;
  delete RunMetadata_reflection_;
}

void protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto() {
  static bool already_here = false;
  if (already_here) return;
  already_here = true;
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto();
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
    "\n%tensorflow/core/protobuf/config.proto\022"
    "\ntensorflow\032*tensorflow/core/framework/c"
    "ost_graph.proto\032*tensorflow/core/framewo"
    "rk/step_stats.proto\"\204\001\n\nGPUOptions\022\'\n\037pe"
    "r_process_gpu_memory_fraction\030\001 \001(\001\022\026\n\016a"
    "llocator_type\030\002 \001(\t\022\037\n\027deferred_deletion"
    "_bytes\030\003 \001(\003\022\024\n\014allow_growth\030\004 \001(\010\"\323\001\n\020O"
    "ptimizerOptions\022+\n#do_common_subexpressi"
    "on_elimination\030\001 \001(\010\022\033\n\023do_constant_fold"
    "ing\030\002 \001(\010\022\034\n\024do_function_inlining\030\004 \001(\010\022"
    "5\n\topt_level\030\003 \001(\0162\".tensorflow.Optimize"
    "rOptions.Level\" \n\005Level\022\006\n\002L1\020\000\022\017\n\002L0\020\377\377"
    "\377\377\377\377\377\377\377\001\"\340\001\n\014GraphOptions\022\036\n\026enable_recv"
    "_scheduling\030\002 \001(\010\0227\n\021optimizer_options\030\003"
    " \001(\0132\034.tensorflow.OptimizerOptions\022\030\n\020bu"
    "ild_cost_model\030\004 \001(\003\022\024\n\014infer_shapes\030\005 \001"
    "(\010\022\032\n\022place_pruned_graph\030\006 \001(\010J\004\010\001\020\002R%sk"
    "ip_common_subexpression_elimination\",\n\025T"
    "hreadPoolOptionProto\022\023\n\013num_threads\030\001 \001("
    "\005\"\244\004\n\013ConfigProto\022>\n\014device_count\030\001 \003(\0132"
    "(.tensorflow.ConfigProto.DeviceCountEntr"
    "y\022$\n\034intra_op_parallelism_threads\030\002 \001(\005\022"
    "$\n\034inter_op_parallelism_threads\030\005 \001(\005\022\037\n"
    "\027use_per_session_threads\030\t \001(\010\022G\n\034sessio"
    "n_inter_op_thread_pool\030\014 \003(\0132!.tensorflo"
    "w.ThreadPoolOptionProto\022\030\n\020placement_per"
    "iod\030\003 \001(\005\022\026\n\016device_filters\030\004 \003(\t\022+\n\013gpu"
    "_options\030\006 \001(\0132\026.tensorflow.GPUOptions\022\034"
    "\n\024allow_soft_placement\030\007 \001(\010\022\034\n\024log_devi"
    "ce_placement\030\010 \001(\010\022/\n\rgraph_options\030\n \001("
    "\0132\030.tensorflow.GraphOptions\022\037\n\027operation"
    "_timeout_in_ms\030\013 \001(\003\0322\n\020DeviceCountEntry"
    "\022\013\n\003key\030\001 \001(\t\022\r\n\005value\030\002 \001(\005:\0028\001\"a\n\020Debu"
    "gTensorWatch\022\021\n\tnode_name\030\001 \001(\t\022\023\n\013outpu"
    "t_slot\030\002 \001(\005\022\021\n\tdebug_ops\030\003 \003(\t\022\022\n\ndebug"
    "_urls\030\004 \003(\t\"\214\002\n\nRunOptions\0226\n\013trace_leve"
    "l\030\001 \001(\0162!.tensorflow.RunOptions.TraceLev"
    "el\022\025\n\rtimeout_in_ms\030\002 \001(\003\022\034\n\024inter_op_th"
    "read_pool\030\003 \001(\005\022=\n\027debug_tensor_watch_op"
    "ts\030\004 \003(\0132\034.tensorflow.DebugTensorWatch\"R"
    "\n\nTraceLevel\022\014\n\010NO_TRACE\020\000\022\022\n\016SOFTWARE_T"
    "RACE\020\001\022\022\n\016HARDWARE_TRACE\020\002\022\016\n\nFULL_TRACE"
    "\020\003\"f\n\013RunMetadata\022)\n\nstep_stats\030\001 \001(\0132\025."
    "tensorflow.StepStats\022,\n\ncost_graph\030\002 \001(\013"
    "2\030.tensorflow.CostGraphDefB-\n\030org.tensor"
    "flow.frameworkB\014ConfigProtosP\001\370\001\001b\006proto"
    "3", 1841);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow/core/protobuf/config.proto", &protobuf_RegisterTypes);
  GPUOptions::default_instance_ = new GPUOptions();
  OptimizerOptions::default_instance_ = new OptimizerOptions();
  GraphOptions::default_instance_ = new GraphOptions();
  ThreadPoolOptionProto::default_instance_ = new ThreadPoolOptionProto();
  ConfigProto::default_instance_ = new ConfigProto();
  DebugTensorWatch::default_instance_ = new DebugTensorWatch();
  RunOptions::default_instance_ = new RunOptions();
  RunMetadata::default_instance_ = new RunMetadata();
  GPUOptions::default_instance_->InitAsDefaultInstance();
  OptimizerOptions::default_instance_->InitAsDefaultInstance();
  GraphOptions::default_instance_->InitAsDefaultInstance();
  ThreadPoolOptionProto::default_instance_->InitAsDefaultInstance();
  ConfigProto::default_instance_->InitAsDefaultInstance();
  DebugTensorWatch::default_instance_->InitAsDefaultInstance();
  RunOptions::default_instance_->InitAsDefaultInstance();
  RunMetadata::default_instance_->InitAsDefaultInstance();
  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto);
}

// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto {
  StaticDescriptorInitializer_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto() {
    protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto();
  }
} static_descriptor_initializer_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto_;

namespace {

static void MergeFromFail(int line) GOOGLE_ATTRIBUTE_COLD;
static void MergeFromFail(int line) {
  GOOGLE_CHECK(false) << __FILE__ << ":" << line;
}

}  // namespace


// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int GPUOptions::kPerProcessGpuMemoryFractionFieldNumber;
const int GPUOptions::kAllocatorTypeFieldNumber;
const int GPUOptions::kDeferredDeletionBytesFieldNumber;
const int GPUOptions::kAllowGrowthFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

GPUOptions::GPUOptions()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.GPUOptions)
}

GPUOptions::GPUOptions(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.GPUOptions)
}

void GPUOptions::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

GPUOptions::GPUOptions(const GPUOptions& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.GPUOptions)
}

void GPUOptions::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  per_process_gpu_memory_fraction_ = 0;
  allocator_type_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  deferred_deletion_bytes_ = GOOGLE_LONGLONG(0);
  allow_growth_ = false;
}

GPUOptions::~GPUOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.GPUOptions)
  SharedDtor();
}

void GPUOptions::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  allocator_type_.Destroy(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
  if (this != default_instance_) {
  }
}

void GPUOptions::ArenaDtor(void* object) {
  GPUOptions* _this = reinterpret_cast< GPUOptions* >(object);
  (void)_this;
}
void GPUOptions::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void GPUOptions::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* GPUOptions::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return GPUOptions_descriptor_;
}

const GPUOptions& GPUOptions::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto();
  return *default_instance_;
}

GPUOptions* GPUOptions::default_instance_ = NULL;

GPUOptions* GPUOptions::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<GPUOptions>(arena);
}

void GPUOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.GPUOptions)
#if defined(__clang__)
#define ZR_HELPER_(f) \
  _Pragma("clang diagnostic push") \
  _Pragma("clang diagnostic ignored \"-Winvalid-offsetof\"") \
  __builtin_offsetof(GPUOptions, f) \
  _Pragma("clang diagnostic pop")
#else
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<GPUOptions*>(16)->f)
#endif

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  ZR_(deferred_deletion_bytes_, allow_growth_);
  per_process_gpu_memory_fraction_ = 0;
  allocator_type_.ClearToEmpty(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());

#undef ZR_HELPER_
#undef ZR_

}

bool GPUOptions::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.GPUOptions)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional double per_process_gpu_memory_fraction = 1;
      case 1: {
        if (tag == 9) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   double, ::google::protobuf::internal::WireFormatLite::TYPE_DOUBLE>(
                 input, &per_process_gpu_memory_fraction_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_allocator_type;
        break;
      }

      // optional string allocator_type = 2;
      case 2: {
        if (tag == 18) {
         parse_allocator_type:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_allocator_type()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->allocator_type().data(), this->allocator_type().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.GPUOptions.allocator_type"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_deferred_deletion_bytes;
        break;
      }

      // optional int64 deferred_deletion_bytes = 3;
      case 3: {
        if (tag == 24) {
         parse_deferred_deletion_bytes:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &deferred_deletion_bytes_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(32)) goto parse_allow_growth;
        break;
      }

      // optional bool allow_growth = 4;
      case 4: {
        if (tag == 32) {
         parse_allow_growth:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &allow_growth_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.GPUOptions)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.GPUOptions)
  return false;
#undef DO_
}

void GPUOptions::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.GPUOptions)
  // optional double per_process_gpu_memory_fraction = 1;
  if (this->per_process_gpu_memory_fraction() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteDouble(1, this->per_process_gpu_memory_fraction(), output);
  }

  // optional string allocator_type = 2;
  if (this->allocator_type().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->allocator_type().data(), this->allocator_type().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.GPUOptions.allocator_type");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      2, this->allocator_type(), output);
  }

  // optional int64 deferred_deletion_bytes = 3;
  if (this->deferred_deletion_bytes() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(3, this->deferred_deletion_bytes(), output);
  }

  // optional bool allow_growth = 4;
  if (this->allow_growth() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(4, this->allow_growth(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.GPUOptions)
}

::google::protobuf::uint8* GPUOptions::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.GPUOptions)
  // optional double per_process_gpu_memory_fraction = 1;
  if (this->per_process_gpu_memory_fraction() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteDoubleToArray(1, this->per_process_gpu_memory_fraction(), target);
  }

  // optional string allocator_type = 2;
  if (this->allocator_type().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->allocator_type().data(), this->allocator_type().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.GPUOptions.allocator_type");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        2, this->allocator_type(), target);
  }

  // optional int64 deferred_deletion_bytes = 3;
  if (this->deferred_deletion_bytes() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(3, this->deferred_deletion_bytes(), target);
  }

  // optional bool allow_growth = 4;
  if (this->allow_growth() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(4, this->allow_growth(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.GPUOptions)
  return target;
}

int GPUOptions::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.GPUOptions)
  int total_size = 0;

  // optional double per_process_gpu_memory_fraction = 1;
  if (this->per_process_gpu_memory_fraction() != 0) {
    total_size += 1 + 8;
  }

  // optional string allocator_type = 2;
  if (this->allocator_type().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->allocator_type());
  }

  // optional int64 deferred_deletion_bytes = 3;
  if (this->deferred_deletion_bytes() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->deferred_deletion_bytes());
  }

  // optional bool allow_growth = 4;
  if (this->allow_growth() != 0) {
    total_size += 1 + 1;
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void GPUOptions::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.GPUOptions)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const GPUOptions* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const GPUOptions>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.GPUOptions)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.GPUOptions)
    MergeFrom(*source);
  }
}

void GPUOptions::MergeFrom(const GPUOptions& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.GPUOptions)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.per_process_gpu_memory_fraction() != 0) {
    set_per_process_gpu_memory_fraction(from.per_process_gpu_memory_fraction());
  }
  if (from.allocator_type().size() > 0) {
    set_allocator_type(from.allocator_type());
  }
  if (from.deferred_deletion_bytes() != 0) {
    set_deferred_deletion_bytes(from.deferred_deletion_bytes());
  }
  if (from.allow_growth() != 0) {
    set_allow_growth(from.allow_growth());
  }
}

void GPUOptions::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.GPUOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void GPUOptions::CopyFrom(const GPUOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.GPUOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool GPUOptions::IsInitialized() const {

  return true;
}

void GPUOptions::Swap(GPUOptions* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    GPUOptions temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void GPUOptions::UnsafeArenaSwap(GPUOptions* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void GPUOptions::InternalSwap(GPUOptions* other) {
  std::swap(per_process_gpu_memory_fraction_, other->per_process_gpu_memory_fraction_);
  allocator_type_.Swap(&other->allocator_type_);
  std::swap(deferred_deletion_bytes_, other->deferred_deletion_bytes_);
  std::swap(allow_growth_, other->allow_growth_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata GPUOptions::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = GPUOptions_descriptor_;
  metadata.reflection = GPUOptions_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// GPUOptions

// optional double per_process_gpu_memory_fraction = 1;
void GPUOptions::clear_per_process_gpu_memory_fraction() {
  per_process_gpu_memory_fraction_ = 0;
}
 double GPUOptions::per_process_gpu_memory_fraction() const {
  // @@protoc_insertion_point(field_get:tensorflow.GPUOptions.per_process_gpu_memory_fraction)
  return per_process_gpu_memory_fraction_;
}
 void GPUOptions::set_per_process_gpu_memory_fraction(double value) {
  
  per_process_gpu_memory_fraction_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.GPUOptions.per_process_gpu_memory_fraction)
}

// optional string allocator_type = 2;
void GPUOptions::clear_allocator_type() {
  allocator_type_.ClearToEmpty(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
 const ::std::string& GPUOptions::allocator_type() const {
  // @@protoc_insertion_point(field_get:tensorflow.GPUOptions.allocator_type)
  return allocator_type_.Get(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void GPUOptions::set_allocator_type(const ::std::string& value) {
  
  allocator_type_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value, GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set:tensorflow.GPUOptions.allocator_type)
}
 void GPUOptions::set_allocator_type(const char* value) {
  
  allocator_type_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value),
              GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_char:tensorflow.GPUOptions.allocator_type)
}
 void GPUOptions::set_allocator_type(const char* value,
    size_t size) {
  
  allocator_type_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size), GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_pointer:tensorflow.GPUOptions.allocator_type)
}
 ::std::string* GPUOptions::mutable_allocator_type() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.GPUOptions.allocator_type)
  return allocator_type_.Mutable(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
 ::std::string* GPUOptions::release_allocator_type() {
  // @@protoc_insertion_point(field_release:tensorflow.GPUOptions.allocator_type)
  
  return allocator_type_.Release(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
 ::std::string* GPUOptions::unsafe_arena_release_allocator_type() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.GPUOptions.allocator_type)
  GOOGLE_DCHECK(GetArenaNoVirtual() != NULL);
  
  return allocator_type_.UnsafeArenaRelease(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      GetArenaNoVirtual());
}
 void GPUOptions::set_allocated_allocator_type(::std::string* allocator_type) {
  if (allocator_type != NULL) {
    
  } else {
    
  }
  allocator_type_.SetAllocated(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), allocator_type,
      GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_allocated:tensorflow.GPUOptions.allocator_type)
}
 void GPUOptions::unsafe_arena_set_allocated_allocator_type(
    ::std::string* allocator_type) {
  GOOGLE_DCHECK(GetArenaNoVirtual() != NULL);
  if (allocator_type != NULL) {
    
  } else {
    
  }
  allocator_type_.UnsafeArenaSetAllocated(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      allocator_type, GetArenaNoVirtual());
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.GPUOptions.allocator_type)
}

// optional int64 deferred_deletion_bytes = 3;
void GPUOptions::clear_deferred_deletion_bytes() {
  deferred_deletion_bytes_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 GPUOptions::deferred_deletion_bytes() const {
  // @@protoc_insertion_point(field_get:tensorflow.GPUOptions.deferred_deletion_bytes)
  return deferred_deletion_bytes_;
}
 void GPUOptions::set_deferred_deletion_bytes(::google::protobuf::int64 value) {
  
  deferred_deletion_bytes_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.GPUOptions.deferred_deletion_bytes)
}

// optional bool allow_growth = 4;
void GPUOptions::clear_allow_growth() {
  allow_growth_ = false;
}
 bool GPUOptions::allow_growth() const {
  // @@protoc_insertion_point(field_get:tensorflow.GPUOptions.allow_growth)
  return allow_growth_;
}
 void GPUOptions::set_allow_growth(bool value) {
  
  allow_growth_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.GPUOptions.allow_growth)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

const ::google::protobuf::EnumDescriptor* OptimizerOptions_Level_descriptor() {
  protobuf_AssignDescriptorsOnce();
  return OptimizerOptions_Level_descriptor_;
}
bool OptimizerOptions_Level_IsValid(int value) {
  switch(value) {
    case -1:
    case 0:
      return true;
    default:
      return false;
  }
}

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const OptimizerOptions_Level OptimizerOptions::L1;
const OptimizerOptions_Level OptimizerOptions::L0;
const OptimizerOptions_Level OptimizerOptions::Level_MIN;
const OptimizerOptions_Level OptimizerOptions::Level_MAX;
const int OptimizerOptions::Level_ARRAYSIZE;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int OptimizerOptions::kDoCommonSubexpressionEliminationFieldNumber;
const int OptimizerOptions::kDoConstantFoldingFieldNumber;
const int OptimizerOptions::kDoFunctionInliningFieldNumber;
const int OptimizerOptions::kOptLevelFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

OptimizerOptions::OptimizerOptions()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.OptimizerOptions)
}

OptimizerOptions::OptimizerOptions(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.OptimizerOptions)
}

void OptimizerOptions::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

OptimizerOptions::OptimizerOptions(const OptimizerOptions& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.OptimizerOptions)
}

void OptimizerOptions::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  do_common_subexpression_elimination_ = false;
  do_constant_folding_ = false;
  do_function_inlining_ = false;
  opt_level_ = 0;
}

OptimizerOptions::~OptimizerOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.OptimizerOptions)
  SharedDtor();
}

void OptimizerOptions::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  if (this != default_instance_) {
  }
}

void OptimizerOptions::ArenaDtor(void* object) {
  OptimizerOptions* _this = reinterpret_cast< OptimizerOptions* >(object);
  (void)_this;
}
void OptimizerOptions::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void OptimizerOptions::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* OptimizerOptions::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return OptimizerOptions_descriptor_;
}

const OptimizerOptions& OptimizerOptions::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto();
  return *default_instance_;
}

OptimizerOptions* OptimizerOptions::default_instance_ = NULL;

OptimizerOptions* OptimizerOptions::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<OptimizerOptions>(arena);
}

void OptimizerOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.OptimizerOptions)
#if defined(__clang__)
#define ZR_HELPER_(f) \
  _Pragma("clang diagnostic push") \
  _Pragma("clang diagnostic ignored \"-Winvalid-offsetof\"") \
  __builtin_offsetof(OptimizerOptions, f) \
  _Pragma("clang diagnostic pop")
#else
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<OptimizerOptions*>(16)->f)
#endif

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  ZR_(do_common_subexpression_elimination_, opt_level_);

#undef ZR_HELPER_
#undef ZR_

}

bool OptimizerOptions::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.OptimizerOptions)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional bool do_common_subexpression_elimination = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &do_common_subexpression_elimination_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_do_constant_folding;
        break;
      }

      // optional bool do_constant_folding = 2;
      case 2: {
        if (tag == 16) {
         parse_do_constant_folding:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &do_constant_folding_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_opt_level;
        break;
      }

      // optional .tensorflow.OptimizerOptions.Level opt_level = 3;
      case 3: {
        if (tag == 24) {
         parse_opt_level:
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          set_opt_level(static_cast< ::tensorflow::OptimizerOptions_Level >(value));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(32)) goto parse_do_function_inlining;
        break;
      }

      // optional bool do_function_inlining = 4;
      case 4: {
        if (tag == 32) {
         parse_do_function_inlining:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &do_function_inlining_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.OptimizerOptions)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.OptimizerOptions)
  return false;
#undef DO_
}

void OptimizerOptions::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.OptimizerOptions)
  // optional bool do_common_subexpression_elimination = 1;
  if (this->do_common_subexpression_elimination() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(1, this->do_common_subexpression_elimination(), output);
  }

  // optional bool do_constant_folding = 2;
  if (this->do_constant_folding() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(2, this->do_constant_folding(), output);
  }

  // optional .tensorflow.OptimizerOptions.Level opt_level = 3;
  if (this->opt_level() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      3, this->opt_level(), output);
  }

  // optional bool do_function_inlining = 4;
  if (this->do_function_inlining() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(4, this->do_function_inlining(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.OptimizerOptions)
}

::google::protobuf::uint8* OptimizerOptions::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.OptimizerOptions)
  // optional bool do_common_subexpression_elimination = 1;
  if (this->do_common_subexpression_elimination() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(1, this->do_common_subexpression_elimination(), target);
  }

  // optional bool do_constant_folding = 2;
  if (this->do_constant_folding() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(2, this->do_constant_folding(), target);
  }

  // optional .tensorflow.OptimizerOptions.Level opt_level = 3;
  if (this->opt_level() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      3, this->opt_level(), target);
  }

  // optional bool do_function_inlining = 4;
  if (this->do_function_inlining() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(4, this->do_function_inlining(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.OptimizerOptions)
  return target;
}

int OptimizerOptions::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.OptimizerOptions)
  int total_size = 0;

  // optional bool do_common_subexpression_elimination = 1;
  if (this->do_common_subexpression_elimination() != 0) {
    total_size += 1 + 1;
  }

  // optional bool do_constant_folding = 2;
  if (this->do_constant_folding() != 0) {
    total_size += 1 + 1;
  }

  // optional bool do_function_inlining = 4;
  if (this->do_function_inlining() != 0) {
    total_size += 1 + 1;
  }

  // optional .tensorflow.OptimizerOptions.Level opt_level = 3;
  if (this->opt_level() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::EnumSize(this->opt_level());
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void OptimizerOptions::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.OptimizerOptions)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const OptimizerOptions* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const OptimizerOptions>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.OptimizerOptions)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.OptimizerOptions)
    MergeFrom(*source);
  }
}

void OptimizerOptions::MergeFrom(const OptimizerOptions& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.OptimizerOptions)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.do_common_subexpression_elimination() != 0) {
    set_do_common_subexpression_elimination(from.do_common_subexpression_elimination());
  }
  if (from.do_constant_folding() != 0) {
    set_do_constant_folding(from.do_constant_folding());
  }
  if (from.do_function_inlining() != 0) {
    set_do_function_inlining(from.do_function_inlining());
  }
  if (from.opt_level() != 0) {
    set_opt_level(from.opt_level());
  }
}

void OptimizerOptions::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.OptimizerOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void OptimizerOptions::CopyFrom(const OptimizerOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.OptimizerOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool OptimizerOptions::IsInitialized() const {

  return true;
}

void OptimizerOptions::Swap(OptimizerOptions* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    OptimizerOptions temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void OptimizerOptions::UnsafeArenaSwap(OptimizerOptions* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void OptimizerOptions::InternalSwap(OptimizerOptions* other) {
  std::swap(do_common_subexpression_elimination_, other->do_common_subexpression_elimination_);
  std::swap(do_constant_folding_, other->do_constant_folding_);
  std::swap(do_function_inlining_, other->do_function_inlining_);
  std::swap(opt_level_, other->opt_level_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata OptimizerOptions::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = OptimizerOptions_descriptor_;
  metadata.reflection = OptimizerOptions_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// OptimizerOptions

// optional bool do_common_subexpression_elimination = 1;
void OptimizerOptions::clear_do_common_subexpression_elimination() {
  do_common_subexpression_elimination_ = false;
}
 bool OptimizerOptions::do_common_subexpression_elimination() const {
  // @@protoc_insertion_point(field_get:tensorflow.OptimizerOptions.do_common_subexpression_elimination)
  return do_common_subexpression_elimination_;
}
 void OptimizerOptions::set_do_common_subexpression_elimination(bool value) {
  
  do_common_subexpression_elimination_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.OptimizerOptions.do_common_subexpression_elimination)
}

// optional bool do_constant_folding = 2;
void OptimizerOptions::clear_do_constant_folding() {
  do_constant_folding_ = false;
}
 bool OptimizerOptions::do_constant_folding() const {
  // @@protoc_insertion_point(field_get:tensorflow.OptimizerOptions.do_constant_folding)
  return do_constant_folding_;
}
 void OptimizerOptions::set_do_constant_folding(bool value) {
  
  do_constant_folding_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.OptimizerOptions.do_constant_folding)
}

// optional bool do_function_inlining = 4;
void OptimizerOptions::clear_do_function_inlining() {
  do_function_inlining_ = false;
}
 bool OptimizerOptions::do_function_inlining() const {
  // @@protoc_insertion_point(field_get:tensorflow.OptimizerOptions.do_function_inlining)
  return do_function_inlining_;
}
 void OptimizerOptions::set_do_function_inlining(bool value) {
  
  do_function_inlining_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.OptimizerOptions.do_function_inlining)
}

// optional .tensorflow.OptimizerOptions.Level opt_level = 3;
void OptimizerOptions::clear_opt_level() {
  opt_level_ = 0;
}
 ::tensorflow::OptimizerOptions_Level OptimizerOptions::opt_level() const {
  // @@protoc_insertion_point(field_get:tensorflow.OptimizerOptions.opt_level)
  return static_cast< ::tensorflow::OptimizerOptions_Level >(opt_level_);
}
 void OptimizerOptions::set_opt_level(::tensorflow::OptimizerOptions_Level value) {
  
  opt_level_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.OptimizerOptions.opt_level)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

void GraphOptions::_slow_mutable_optimizer_options() {
  optimizer_options_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::OptimizerOptions >(
      GetArenaNoVirtual());
}
::tensorflow::OptimizerOptions* GraphOptions::_slow_release_optimizer_options() {
  if (optimizer_options_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::OptimizerOptions* temp = new ::tensorflow::OptimizerOptions;
    temp->MergeFrom(*optimizer_options_);
    optimizer_options_ = NULL;
    return temp;
  }
}
::tensorflow::OptimizerOptions* GraphOptions::unsafe_arena_release_optimizer_options() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.GraphOptions.optimizer_options)
  
  ::tensorflow::OptimizerOptions* temp = optimizer_options_;
  optimizer_options_ = NULL;
  return temp;
}
void GraphOptions::_slow_set_allocated_optimizer_options(
    ::google::protobuf::Arena* message_arena, ::tensorflow::OptimizerOptions** optimizer_options) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*optimizer_options) == NULL) {
      message_arena->Own(*optimizer_options);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*optimizer_options)) {
      ::tensorflow::OptimizerOptions* new_optimizer_options = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::OptimizerOptions >(
            message_arena);
      new_optimizer_options->CopyFrom(**optimizer_options);
      *optimizer_options = new_optimizer_options;
    }
}
void GraphOptions::unsafe_arena_set_allocated_optimizer_options(
    ::tensorflow::OptimizerOptions* optimizer_options) {
  if (GetArenaNoVirtual() == NULL) {
    delete optimizer_options_;
  }
  optimizer_options_ = optimizer_options;
  if (optimizer_options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.GraphOptions.optimizer_options)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int GraphOptions::kEnableRecvSchedulingFieldNumber;
const int GraphOptions::kOptimizerOptionsFieldNumber;
const int GraphOptions::kBuildCostModelFieldNumber;
const int GraphOptions::kInferShapesFieldNumber;
const int GraphOptions::kPlacePrunedGraphFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

GraphOptions::GraphOptions()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.GraphOptions)
}

GraphOptions::GraphOptions(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.GraphOptions)
}

void GraphOptions::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  optimizer_options_ = const_cast< ::tensorflow::OptimizerOptions*>(&::tensorflow::OptimizerOptions::default_instance());
}

GraphOptions::GraphOptions(const GraphOptions& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.GraphOptions)
}

void GraphOptions::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  enable_recv_scheduling_ = false;
  optimizer_options_ = NULL;
  build_cost_model_ = GOOGLE_LONGLONG(0);
  infer_shapes_ = false;
  place_pruned_graph_ = false;
}

GraphOptions::~GraphOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.GraphOptions)
  SharedDtor();
}

void GraphOptions::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  if (this != default_instance_) {
    delete optimizer_options_;
  }
}

void GraphOptions::ArenaDtor(void* object) {
  GraphOptions* _this = reinterpret_cast< GraphOptions* >(object);
  (void)_this;
}
void GraphOptions::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void GraphOptions::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* GraphOptions::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return GraphOptions_descriptor_;
}

const GraphOptions& GraphOptions::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto();
  return *default_instance_;
}

GraphOptions* GraphOptions::default_instance_ = NULL;

GraphOptions* GraphOptions::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<GraphOptions>(arena);
}

void GraphOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.GraphOptions)
#if defined(__clang__)
#define ZR_HELPER_(f) \
  _Pragma("clang diagnostic push") \
  _Pragma("clang diagnostic ignored \"-Winvalid-offsetof\"") \
  __builtin_offsetof(GraphOptions, f) \
  _Pragma("clang diagnostic pop")
#else
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<GraphOptions*>(16)->f)
#endif

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  ZR_(build_cost_model_, place_pruned_graph_);
  if (GetArenaNoVirtual() == NULL && optimizer_options_ != NULL) delete optimizer_options_;
  optimizer_options_ = NULL;

#undef ZR_HELPER_
#undef ZR_

}

bool GraphOptions::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.GraphOptions)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional bool enable_recv_scheduling = 2;
      case 2: {
        if (tag == 16) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &enable_recv_scheduling_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(26)) goto parse_optimizer_options;
        break;
      }

      // optional .tensorflow.OptimizerOptions optimizer_options = 3;
      case 3: {
        if (tag == 26) {
         parse_optimizer_options:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_optimizer_options()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(32)) goto parse_build_cost_model;
        break;
      }

      // optional int64 build_cost_model = 4;
      case 4: {
        if (tag == 32) {
         parse_build_cost_model:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &build_cost_model_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(40)) goto parse_infer_shapes;
        break;
      }

      // optional bool infer_shapes = 5;
      case 5: {
        if (tag == 40) {
         parse_infer_shapes:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &infer_shapes_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(48)) goto parse_place_pruned_graph;
        break;
      }

      // optional bool place_pruned_graph = 6;
      case 6: {
        if (tag == 48) {
         parse_place_pruned_graph:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &place_pruned_graph_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.GraphOptions)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.GraphOptions)
  return false;
#undef DO_
}

void GraphOptions::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.GraphOptions)
  // optional bool enable_recv_scheduling = 2;
  if (this->enable_recv_scheduling() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(2, this->enable_recv_scheduling(), output);
  }

  // optional .tensorflow.OptimizerOptions optimizer_options = 3;
  if (this->has_optimizer_options()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, *this->optimizer_options_, output);
  }

  // optional int64 build_cost_model = 4;
  if (this->build_cost_model() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(4, this->build_cost_model(), output);
  }

  // optional bool infer_shapes = 5;
  if (this->infer_shapes() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(5, this->infer_shapes(), output);
  }

  // optional bool place_pruned_graph = 6;
  if (this->place_pruned_graph() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(6, this->place_pruned_graph(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.GraphOptions)
}

::google::protobuf::uint8* GraphOptions::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.GraphOptions)
  // optional bool enable_recv_scheduling = 2;
  if (this->enable_recv_scheduling() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(2, this->enable_recv_scheduling(), target);
  }

  // optional .tensorflow.OptimizerOptions optimizer_options = 3;
  if (this->has_optimizer_options()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        3, *this->optimizer_options_, target);
  }

  // optional int64 build_cost_model = 4;
  if (this->build_cost_model() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(4, this->build_cost_model(), target);
  }

  // optional bool infer_shapes = 5;
  if (this->infer_shapes() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(5, this->infer_shapes(), target);
  }

  // optional bool place_pruned_graph = 6;
  if (this->place_pruned_graph() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(6, this->place_pruned_graph(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.GraphOptions)
  return target;
}

int GraphOptions::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.GraphOptions)
  int total_size = 0;

  // optional bool enable_recv_scheduling = 2;
  if (this->enable_recv_scheduling() != 0) {
    total_size += 1 + 1;
  }

  // optional .tensorflow.OptimizerOptions optimizer_options = 3;
  if (this->has_optimizer_options()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->optimizer_options_);
  }

  // optional int64 build_cost_model = 4;
  if (this->build_cost_model() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->build_cost_model());
  }

  // optional bool infer_shapes = 5;
  if (this->infer_shapes() != 0) {
    total_size += 1 + 1;
  }

  // optional bool place_pruned_graph = 6;
  if (this->place_pruned_graph() != 0) {
    total_size += 1 + 1;
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void GraphOptions::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.GraphOptions)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const GraphOptions* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const GraphOptions>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.GraphOptions)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.GraphOptions)
    MergeFrom(*source);
  }
}

void GraphOptions::MergeFrom(const GraphOptions& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.GraphOptions)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.enable_recv_scheduling() != 0) {
    set_enable_recv_scheduling(from.enable_recv_scheduling());
  }
  if (from.has_optimizer_options()) {
    mutable_optimizer_options()->::tensorflow::OptimizerOptions::MergeFrom(from.optimizer_options());
  }
  if (from.build_cost_model() != 0) {
    set_build_cost_model(from.build_cost_model());
  }
  if (from.infer_shapes() != 0) {
    set_infer_shapes(from.infer_shapes());
  }
  if (from.place_pruned_graph() != 0) {
    set_place_pruned_graph(from.place_pruned_graph());
  }
}

void GraphOptions::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.GraphOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void GraphOptions::CopyFrom(const GraphOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.GraphOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool GraphOptions::IsInitialized() const {

  return true;
}

void GraphOptions::Swap(GraphOptions* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    GraphOptions temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void GraphOptions::UnsafeArenaSwap(GraphOptions* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void GraphOptions::InternalSwap(GraphOptions* other) {
  std::swap(enable_recv_scheduling_, other->enable_recv_scheduling_);
  std::swap(optimizer_options_, other->optimizer_options_);
  std::swap(build_cost_model_, other->build_cost_model_);
  std::swap(infer_shapes_, other->infer_shapes_);
  std::swap(place_pruned_graph_, other->place_pruned_graph_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata GraphOptions::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = GraphOptions_descriptor_;
  metadata.reflection = GraphOptions_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// GraphOptions

// optional bool enable_recv_scheduling = 2;
void GraphOptions::clear_enable_recv_scheduling() {
  enable_recv_scheduling_ = false;
}
 bool GraphOptions::enable_recv_scheduling() const {
  // @@protoc_insertion_point(field_get:tensorflow.GraphOptions.enable_recv_scheduling)
  return enable_recv_scheduling_;
}
 void GraphOptions::set_enable_recv_scheduling(bool value) {
  
  enable_recv_scheduling_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.GraphOptions.enable_recv_scheduling)
}

// optional .tensorflow.OptimizerOptions optimizer_options = 3;
bool GraphOptions::has_optimizer_options() const {
  return !_is_default_instance_ && optimizer_options_ != NULL;
}
void GraphOptions::clear_optimizer_options() {
  if (GetArenaNoVirtual() == NULL && optimizer_options_ != NULL) delete optimizer_options_;
  optimizer_options_ = NULL;
}
const ::tensorflow::OptimizerOptions& GraphOptions::optimizer_options() const {
  // @@protoc_insertion_point(field_get:tensorflow.GraphOptions.optimizer_options)
  return optimizer_options_ != NULL ? *optimizer_options_ : *default_instance_->optimizer_options_;
}
::tensorflow::OptimizerOptions* GraphOptions::mutable_optimizer_options() {
  
  if (optimizer_options_ == NULL) {
    _slow_mutable_optimizer_options();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.GraphOptions.optimizer_options)
  return optimizer_options_;
}
::tensorflow::OptimizerOptions* GraphOptions::release_optimizer_options() {
  // @@protoc_insertion_point(field_release:tensorflow.GraphOptions.optimizer_options)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_optimizer_options();
  } else {
    ::tensorflow::OptimizerOptions* temp = optimizer_options_;
    optimizer_options_ = NULL;
    return temp;
  }
}
 void GraphOptions::set_allocated_optimizer_options(::tensorflow::OptimizerOptions* optimizer_options) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete optimizer_options_;
  }
  if (optimizer_options != NULL) {
    _slow_set_allocated_optimizer_options(message_arena, &optimizer_options);
  }
  optimizer_options_ = optimizer_options;
  if (optimizer_options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.GraphOptions.optimizer_options)
}

// optional int64 build_cost_model = 4;
void GraphOptions::clear_build_cost_model() {
  build_cost_model_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 GraphOptions::build_cost_model() const {
  // @@protoc_insertion_point(field_get:tensorflow.GraphOptions.build_cost_model)
  return build_cost_model_;
}
 void GraphOptions::set_build_cost_model(::google::protobuf::int64 value) {
  
  build_cost_model_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.GraphOptions.build_cost_model)
}

// optional bool infer_shapes = 5;
void GraphOptions::clear_infer_shapes() {
  infer_shapes_ = false;
}
 bool GraphOptions::infer_shapes() const {
  // @@protoc_insertion_point(field_get:tensorflow.GraphOptions.infer_shapes)
  return infer_shapes_;
}
 void GraphOptions::set_infer_shapes(bool value) {
  
  infer_shapes_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.GraphOptions.infer_shapes)
}

// optional bool place_pruned_graph = 6;
void GraphOptions::clear_place_pruned_graph() {
  place_pruned_graph_ = false;
}
 bool GraphOptions::place_pruned_graph() const {
  // @@protoc_insertion_point(field_get:tensorflow.GraphOptions.place_pruned_graph)
  return place_pruned_graph_;
}
 void GraphOptions::set_place_pruned_graph(bool value) {
  
  place_pruned_graph_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.GraphOptions.place_pruned_graph)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ThreadPoolOptionProto::kNumThreadsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ThreadPoolOptionProto::ThreadPoolOptionProto()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.ThreadPoolOptionProto)
}

ThreadPoolOptionProto::ThreadPoolOptionProto(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.ThreadPoolOptionProto)
}

void ThreadPoolOptionProto::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

ThreadPoolOptionProto::ThreadPoolOptionProto(const ThreadPoolOptionProto& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.ThreadPoolOptionProto)
}

void ThreadPoolOptionProto::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  num_threads_ = 0;
}

ThreadPoolOptionProto::~ThreadPoolOptionProto() {
  // @@protoc_insertion_point(destructor:tensorflow.ThreadPoolOptionProto)
  SharedDtor();
}

void ThreadPoolOptionProto::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  if (this != default_instance_) {
  }
}

void ThreadPoolOptionProto::ArenaDtor(void* object) {
  ThreadPoolOptionProto* _this = reinterpret_cast< ThreadPoolOptionProto* >(object);
  (void)_this;
}
void ThreadPoolOptionProto::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void ThreadPoolOptionProto::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ThreadPoolOptionProto::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ThreadPoolOptionProto_descriptor_;
}

const ThreadPoolOptionProto& ThreadPoolOptionProto::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto();
  return *default_instance_;
}

ThreadPoolOptionProto* ThreadPoolOptionProto::default_instance_ = NULL;

ThreadPoolOptionProto* ThreadPoolOptionProto::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<ThreadPoolOptionProto>(arena);
}

void ThreadPoolOptionProto::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.ThreadPoolOptionProto)
  num_threads_ = 0;
}

bool ThreadPoolOptionProto::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.ThreadPoolOptionProto)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional int32 num_threads = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &num_threads_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.ThreadPoolOptionProto)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.ThreadPoolOptionProto)
  return false;
#undef DO_
}

void ThreadPoolOptionProto::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.ThreadPoolOptionProto)
  // optional int32 num_threads = 1;
  if (this->num_threads() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(1, this->num_threads(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.ThreadPoolOptionProto)
}

::google::protobuf::uint8* ThreadPoolOptionProto::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.ThreadPoolOptionProto)
  // optional int32 num_threads = 1;
  if (this->num_threads() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(1, this->num_threads(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.ThreadPoolOptionProto)
  return target;
}

int ThreadPoolOptionProto::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.ThreadPoolOptionProto)
  int total_size = 0;

  // optional int32 num_threads = 1;
  if (this->num_threads() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->num_threads());
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ThreadPoolOptionProto::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.ThreadPoolOptionProto)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const ThreadPoolOptionProto* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ThreadPoolOptionProto>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.ThreadPoolOptionProto)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.ThreadPoolOptionProto)
    MergeFrom(*source);
  }
}

void ThreadPoolOptionProto::MergeFrom(const ThreadPoolOptionProto& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.ThreadPoolOptionProto)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.num_threads() != 0) {
    set_num_threads(from.num_threads());
  }
}

void ThreadPoolOptionProto::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.ThreadPoolOptionProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ThreadPoolOptionProto::CopyFrom(const ThreadPoolOptionProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.ThreadPoolOptionProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ThreadPoolOptionProto::IsInitialized() const {

  return true;
}

void ThreadPoolOptionProto::Swap(ThreadPoolOptionProto* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    ThreadPoolOptionProto temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void ThreadPoolOptionProto::UnsafeArenaSwap(ThreadPoolOptionProto* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void ThreadPoolOptionProto::InternalSwap(ThreadPoolOptionProto* other) {
  std::swap(num_threads_, other->num_threads_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ThreadPoolOptionProto::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ThreadPoolOptionProto_descriptor_;
  metadata.reflection = ThreadPoolOptionProto_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ThreadPoolOptionProto

// optional int32 num_threads = 1;
void ThreadPoolOptionProto::clear_num_threads() {
  num_threads_ = 0;
}
 ::google::protobuf::int32 ThreadPoolOptionProto::num_threads() const {
  // @@protoc_insertion_point(field_get:tensorflow.ThreadPoolOptionProto.num_threads)
  return num_threads_;
}
 void ThreadPoolOptionProto::set_num_threads(::google::protobuf::int32 value) {
  
  num_threads_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ThreadPoolOptionProto.num_threads)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

void ConfigProto::_slow_mutable_gpu_options() {
  gpu_options_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::GPUOptions >(
      GetArenaNoVirtual());
}
::tensorflow::GPUOptions* ConfigProto::_slow_release_gpu_options() {
  if (gpu_options_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::GPUOptions* temp = new ::tensorflow::GPUOptions;
    temp->MergeFrom(*gpu_options_);
    gpu_options_ = NULL;
    return temp;
  }
}
::tensorflow::GPUOptions* ConfigProto::unsafe_arena_release_gpu_options() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.ConfigProto.gpu_options)
  
  ::tensorflow::GPUOptions* temp = gpu_options_;
  gpu_options_ = NULL;
  return temp;
}
void ConfigProto::_slow_set_allocated_gpu_options(
    ::google::protobuf::Arena* message_arena, ::tensorflow::GPUOptions** gpu_options) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*gpu_options) == NULL) {
      message_arena->Own(*gpu_options);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*gpu_options)) {
      ::tensorflow::GPUOptions* new_gpu_options = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::GPUOptions >(
            message_arena);
      new_gpu_options->CopyFrom(**gpu_options);
      *gpu_options = new_gpu_options;
    }
}
void ConfigProto::unsafe_arena_set_allocated_gpu_options(
    ::tensorflow::GPUOptions* gpu_options) {
  if (GetArenaNoVirtual() == NULL) {
    delete gpu_options_;
  }
  gpu_options_ = gpu_options;
  if (gpu_options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.ConfigProto.gpu_options)
}
void ConfigProto::_slow_mutable_graph_options() {
  graph_options_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::GraphOptions >(
      GetArenaNoVirtual());
}
::tensorflow::GraphOptions* ConfigProto::_slow_release_graph_options() {
  if (graph_options_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::GraphOptions* temp = new ::tensorflow::GraphOptions;
    temp->MergeFrom(*graph_options_);
    graph_options_ = NULL;
    return temp;
  }
}
::tensorflow::GraphOptions* ConfigProto::unsafe_arena_release_graph_options() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.ConfigProto.graph_options)
  
  ::tensorflow::GraphOptions* temp = graph_options_;
  graph_options_ = NULL;
  return temp;
}
void ConfigProto::_slow_set_allocated_graph_options(
    ::google::protobuf::Arena* message_arena, ::tensorflow::GraphOptions** graph_options) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*graph_options) == NULL) {
      message_arena->Own(*graph_options);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*graph_options)) {
      ::tensorflow::GraphOptions* new_graph_options = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::GraphOptions >(
            message_arena);
      new_graph_options->CopyFrom(**graph_options);
      *graph_options = new_graph_options;
    }
}
void ConfigProto::unsafe_arena_set_allocated_graph_options(
    ::tensorflow::GraphOptions* graph_options) {
  if (GetArenaNoVirtual() == NULL) {
    delete graph_options_;
  }
  graph_options_ = graph_options;
  if (graph_options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.ConfigProto.graph_options)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ConfigProto::kDeviceCountFieldNumber;
const int ConfigProto::kIntraOpParallelismThreadsFieldNumber;
const int ConfigProto::kInterOpParallelismThreadsFieldNumber;
const int ConfigProto::kUsePerSessionThreadsFieldNumber;
const int ConfigProto::kSessionInterOpThreadPoolFieldNumber;
const int ConfigProto::kPlacementPeriodFieldNumber;
const int ConfigProto::kDeviceFiltersFieldNumber;
const int ConfigProto::kGpuOptionsFieldNumber;
const int ConfigProto::kAllowSoftPlacementFieldNumber;
const int ConfigProto::kLogDevicePlacementFieldNumber;
const int ConfigProto::kGraphOptionsFieldNumber;
const int ConfigProto::kOperationTimeoutInMsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ConfigProto::ConfigProto()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.ConfigProto)
}

ConfigProto::ConfigProto(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena),
  device_count_(arena),
  session_inter_op_thread_pool_(arena),
  device_filters_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.ConfigProto)
}

void ConfigProto::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  gpu_options_ = const_cast< ::tensorflow::GPUOptions*>(&::tensorflow::GPUOptions::default_instance());
  graph_options_ = const_cast< ::tensorflow::GraphOptions*>(&::tensorflow::GraphOptions::default_instance());
}

ConfigProto::ConfigProto(const ConfigProto& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.ConfigProto)
}

void ConfigProto::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  device_count_.SetAssignDescriptorCallback(
      protobuf_AssignDescriptorsOnce);
  device_count_.SetEntryDescriptor(
      &::tensorflow::ConfigProto_DeviceCountEntry_descriptor_);
  intra_op_parallelism_threads_ = 0;
  inter_op_parallelism_threads_ = 0;
  use_per_session_threads_ = false;
  placement_period_ = 0;
  gpu_options_ = NULL;
  allow_soft_placement_ = false;
  log_device_placement_ = false;
  graph_options_ = NULL;
  operation_timeout_in_ms_ = GOOGLE_LONGLONG(0);
}

ConfigProto::~ConfigProto() {
  // @@protoc_insertion_point(destructor:tensorflow.ConfigProto)
  SharedDtor();
}

void ConfigProto::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  if (this != default_instance_) {
    delete gpu_options_;
    delete graph_options_;
  }
}

void ConfigProto::ArenaDtor(void* object) {
  ConfigProto* _this = reinterpret_cast< ConfigProto* >(object);
  (void)_this;
}
void ConfigProto::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void ConfigProto::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ConfigProto::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return ConfigProto_descriptor_;
}

const ConfigProto& ConfigProto::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto();
  return *default_instance_;
}

ConfigProto* ConfigProto::default_instance_ = NULL;

ConfigProto* ConfigProto::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<ConfigProto>(arena);
}

void ConfigProto::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.ConfigProto)
#if defined(__clang__)
#define ZR_HELPER_(f) \
  _Pragma("clang diagnostic push") \
  _Pragma("clang diagnostic ignored \"-Winvalid-offsetof\"") \
  __builtin_offsetof(ConfigProto, f) \
  _Pragma("clang diagnostic pop")
#else
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<ConfigProto*>(16)->f)
#endif

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  ZR_(intra_op_parallelism_threads_, inter_op_parallelism_threads_);
  ZR_(placement_period_, use_per_session_threads_);
  if (GetArenaNoVirtual() == NULL && gpu_options_ != NULL) delete gpu_options_;
  gpu_options_ = NULL;
  ZR_(allow_soft_placement_, log_device_placement_);
  if (GetArenaNoVirtual() == NULL && graph_options_ != NULL) delete graph_options_;
  graph_options_ = NULL;
  operation_timeout_in_ms_ = GOOGLE_LONGLONG(0);

#undef ZR_HELPER_
#undef ZR_

  device_count_.Clear();
  session_inter_op_thread_pool_.Clear();
  device_filters_.Clear();
}

bool ConfigProto::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.ConfigProto)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // map<string, int32> device_count = 1;
      case 1: {
        if (tag == 10) {
          DO_(input->IncrementRecursionDepth());
         parse_loop_device_count:
          ::google::protobuf::scoped_ptr<ConfigProto_DeviceCountEntry> entry(device_count_.NewEntry());
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
              input, entry.get()));
          (*mutable_device_count())[entry->key()] = *entry->mutable_value();
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            entry->key().data(), entry->key().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.ConfigProto.DeviceCountEntry.key"));
          if (entry->GetArena() != NULL) entry.release();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(10)) goto parse_loop_device_count;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectTag(16)) goto parse_intra_op_parallelism_threads;
        break;
      }

      // optional int32 intra_op_parallelism_threads = 2;
      case 2: {
        if (tag == 16) {
         parse_intra_op_parallelism_threads:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &intra_op_parallelism_threads_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_placement_period;
        break;
      }

      // optional int32 placement_period = 3;
      case 3: {
        if (tag == 24) {
         parse_placement_period:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &placement_period_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_device_filters;
        break;
      }

      // repeated string device_filters = 4;
      case 4: {
        if (tag == 34) {
         parse_device_filters:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->add_device_filters()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->device_filters(this->device_filters_size() - 1).data(),
            this->device_filters(this->device_filters_size() - 1).length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.ConfigProto.device_filters"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_device_filters;
        if (input->ExpectTag(40)) goto parse_inter_op_parallelism_threads;
        break;
      }

      // optional int32 inter_op_parallelism_threads = 5;
      case 5: {
        if (tag == 40) {
         parse_inter_op_parallelism_threads:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &inter_op_parallelism_threads_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(50)) goto parse_gpu_options;
        break;
      }

      // optional .tensorflow.GPUOptions gpu_options = 6;
      case 6: {
        if (tag == 50) {
         parse_gpu_options:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_gpu_options()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(56)) goto parse_allow_soft_placement;
        break;
      }

      // optional bool allow_soft_placement = 7;
      case 7: {
        if (tag == 56) {
         parse_allow_soft_placement:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &allow_soft_placement_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(64)) goto parse_log_device_placement;
        break;
      }

      // optional bool log_device_placement = 8;
      case 8: {
        if (tag == 64) {
         parse_log_device_placement:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &log_device_placement_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(72)) goto parse_use_per_session_threads;
        break;
      }

      // optional bool use_per_session_threads = 9;
      case 9: {
        if (tag == 72) {
         parse_use_per_session_threads:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &use_per_session_threads_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(82)) goto parse_graph_options;
        break;
      }

      // optional .tensorflow.GraphOptions graph_options = 10;
      case 10: {
        if (tag == 82) {
         parse_graph_options:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_graph_options()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(88)) goto parse_operation_timeout_in_ms;
        break;
      }

      // optional int64 operation_timeout_in_ms = 11;
      case 11: {
        if (tag == 88) {
         parse_operation_timeout_in_ms:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &operation_timeout_in_ms_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(98)) goto parse_session_inter_op_thread_pool;
        break;
      }

      // repeated .tensorflow.ThreadPoolOptionProto session_inter_op_thread_pool = 12;
      case 12: {
        if (tag == 98) {
         parse_session_inter_op_thread_pool:
          DO_(input->IncrementRecursionDepth());
         parse_loop_session_inter_op_thread_pool:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_session_inter_op_thread_pool()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(98)) goto parse_loop_session_inter_op_thread_pool;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.ConfigProto)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.ConfigProto)
  return false;
#undef DO_
}

void ConfigProto::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.ConfigProto)
  // map<string, int32> device_count = 1;
  {
    ::google::protobuf::scoped_ptr<ConfigProto_DeviceCountEntry> entry;
    for (::google::protobuf::Map< ::std::string, ::google::protobuf::int32 >::const_iterator
        it = this->device_count().begin();
        it != this->device_count().end(); ++it) {
      if (entry.get() != NULL && entry->GetArena() != NULL) {
        entry.release();
      }
      entry.reset(device_count_.NewEntryWrapper(it->first, it->second));
      ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
          1, *entry, output);
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        it->first.data(), it->first.length(),
        ::google::protobuf::internal::WireFormatLite::SERIALIZE,
        "tensorflow.ConfigProto.DeviceCountEntry.key");
    }
    if (entry.get() != NULL && entry->GetArena() != NULL) {
      entry.release();
    }
  }

  // optional int32 intra_op_parallelism_threads = 2;
  if (this->intra_op_parallelism_threads() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(2, this->intra_op_parallelism_threads(), output);
  }

  // optional int32 placement_period = 3;
  if (this->placement_period() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(3, this->placement_period(), output);
  }

  // repeated string device_filters = 4;
  for (int i = 0; i < this->device_filters_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->device_filters(i).data(), this->device_filters(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.ConfigProto.device_filters");
    ::google::protobuf::internal::WireFormatLite::WriteString(
      4, this->device_filters(i), output);
  }

  // optional int32 inter_op_parallelism_threads = 5;
  if (this->inter_op_parallelism_threads() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(5, this->inter_op_parallelism_threads(), output);
  }

  // optional .tensorflow.GPUOptions gpu_options = 6;
  if (this->has_gpu_options()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      6, *this->gpu_options_, output);
  }

  // optional bool allow_soft_placement = 7;
  if (this->allow_soft_placement() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(7, this->allow_soft_placement(), output);
  }

  // optional bool log_device_placement = 8;
  if (this->log_device_placement() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(8, this->log_device_placement(), output);
  }

  // optional bool use_per_session_threads = 9;
  if (this->use_per_session_threads() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(9, this->use_per_session_threads(), output);
  }

  // optional .tensorflow.GraphOptions graph_options = 10;
  if (this->has_graph_options()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      10, *this->graph_options_, output);
  }

  // optional int64 operation_timeout_in_ms = 11;
  if (this->operation_timeout_in_ms() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(11, this->operation_timeout_in_ms(), output);
  }

  // repeated .tensorflow.ThreadPoolOptionProto session_inter_op_thread_pool = 12;
  for (unsigned int i = 0, n = this->session_inter_op_thread_pool_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      12, this->session_inter_op_thread_pool(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.ConfigProto)
}

::google::protobuf::uint8* ConfigProto::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.ConfigProto)
  // map<string, int32> device_count = 1;
  {
    ::google::protobuf::scoped_ptr<ConfigProto_DeviceCountEntry> entry;
    for (::google::protobuf::Map< ::std::string, ::google::protobuf::int32 >::const_iterator
        it = this->device_count().begin();
        it != this->device_count().end(); ++it) {
      if (entry.get() != NULL && entry->GetArena() != NULL) {
        entry.release();
      }
      entry.reset(device_count_.NewEntryWrapper(it->first, it->second));
      target = ::google::protobuf::internal::WireFormatLite::
          WriteMessageNoVirtualToArray(
              1, *entry, target);
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        it->first.data(), it->first.length(),
        ::google::protobuf::internal::WireFormatLite::SERIALIZE,
        "tensorflow.ConfigProto.DeviceCountEntry.key");
    }
    if (entry.get() != NULL && entry->GetArena() != NULL) {
      entry.release();
    }
  }

  // optional int32 intra_op_parallelism_threads = 2;
  if (this->intra_op_parallelism_threads() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(2, this->intra_op_parallelism_threads(), target);
  }

  // optional int32 placement_period = 3;
  if (this->placement_period() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(3, this->placement_period(), target);
  }

  // repeated string device_filters = 4;
  for (int i = 0; i < this->device_filters_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->device_filters(i).data(), this->device_filters(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.ConfigProto.device_filters");
    target = ::google::protobuf::internal::WireFormatLite::
      WriteStringToArray(4, this->device_filters(i), target);
  }

  // optional int32 inter_op_parallelism_threads = 5;
  if (this->inter_op_parallelism_threads() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(5, this->inter_op_parallelism_threads(), target);
  }

  // optional .tensorflow.GPUOptions gpu_options = 6;
  if (this->has_gpu_options()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        6, *this->gpu_options_, target);
  }

  // optional bool allow_soft_placement = 7;
  if (this->allow_soft_placement() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(7, this->allow_soft_placement(), target);
  }

  // optional bool log_device_placement = 8;
  if (this->log_device_placement() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(8, this->log_device_placement(), target);
  }

  // optional bool use_per_session_threads = 9;
  if (this->use_per_session_threads() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(9, this->use_per_session_threads(), target);
  }

  // optional .tensorflow.GraphOptions graph_options = 10;
  if (this->has_graph_options()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        10, *this->graph_options_, target);
  }

  // optional int64 operation_timeout_in_ms = 11;
  if (this->operation_timeout_in_ms() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(11, this->operation_timeout_in_ms(), target);
  }

  // repeated .tensorflow.ThreadPoolOptionProto session_inter_op_thread_pool = 12;
  for (unsigned int i = 0, n = this->session_inter_op_thread_pool_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        12, this->session_inter_op_thread_pool(i), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.ConfigProto)
  return target;
}

int ConfigProto::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.ConfigProto)
  int total_size = 0;

  // optional int32 intra_op_parallelism_threads = 2;
  if (this->intra_op_parallelism_threads() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->intra_op_parallelism_threads());
  }

  // optional int32 inter_op_parallelism_threads = 5;
  if (this->inter_op_parallelism_threads() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->inter_op_parallelism_threads());
  }

  // optional bool use_per_session_threads = 9;
  if (this->use_per_session_threads() != 0) {
    total_size += 1 + 1;
  }

  // optional int32 placement_period = 3;
  if (this->placement_period() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->placement_period());
  }

  // optional .tensorflow.GPUOptions gpu_options = 6;
  if (this->has_gpu_options()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->gpu_options_);
  }

  // optional bool allow_soft_placement = 7;
  if (this->allow_soft_placement() != 0) {
    total_size += 1 + 1;
  }

  // optional bool log_device_placement = 8;
  if (this->log_device_placement() != 0) {
    total_size += 1 + 1;
  }

  // optional .tensorflow.GraphOptions graph_options = 10;
  if (this->has_graph_options()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->graph_options_);
  }

  // optional int64 operation_timeout_in_ms = 11;
  if (this->operation_timeout_in_ms() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->operation_timeout_in_ms());
  }

  // map<string, int32> device_count = 1;
  total_size += 1 * this->device_count_size();
  {
    ::google::protobuf::scoped_ptr<ConfigProto_DeviceCountEntry> entry;
    for (::google::protobuf::Map< ::std::string, ::google::protobuf::int32 >::const_iterator
        it = this->device_count().begin();
        it != this->device_count().end(); ++it) {
      if (entry.get() != NULL && entry->GetArena() != NULL) {
        entry.release();
      }
      entry.reset(device_count_.NewEntryWrapper(it->first, it->second));
      total_size += ::google::protobuf::internal::WireFormatLite::
          MessageSizeNoVirtual(*entry);
    }
    if (entry.get() != NULL && entry->GetArena() != NULL) {
      entry.release();
    }
  }

  // repeated .tensorflow.ThreadPoolOptionProto session_inter_op_thread_pool = 12;
  total_size += 1 * this->session_inter_op_thread_pool_size();
  for (int i = 0; i < this->session_inter_op_thread_pool_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->session_inter_op_thread_pool(i));
  }

  // repeated string device_filters = 4;
  total_size += 1 * this->device_filters_size();
  for (int i = 0; i < this->device_filters_size(); i++) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
      this->device_filters(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ConfigProto::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.ConfigProto)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const ConfigProto* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const ConfigProto>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.ConfigProto)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.ConfigProto)
    MergeFrom(*source);
  }
}

void ConfigProto::MergeFrom(const ConfigProto& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.ConfigProto)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  device_count_.MergeFrom(from.device_count_);
  session_inter_op_thread_pool_.MergeFrom(from.session_inter_op_thread_pool_);
  device_filters_.MergeFrom(from.device_filters_);
  if (from.intra_op_parallelism_threads() != 0) {
    set_intra_op_parallelism_threads(from.intra_op_parallelism_threads());
  }
  if (from.inter_op_parallelism_threads() != 0) {
    set_inter_op_parallelism_threads(from.inter_op_parallelism_threads());
  }
  if (from.use_per_session_threads() != 0) {
    set_use_per_session_threads(from.use_per_session_threads());
  }
  if (from.placement_period() != 0) {
    set_placement_period(from.placement_period());
  }
  if (from.has_gpu_options()) {
    mutable_gpu_options()->::tensorflow::GPUOptions::MergeFrom(from.gpu_options());
  }
  if (from.allow_soft_placement() != 0) {
    set_allow_soft_placement(from.allow_soft_placement());
  }
  if (from.log_device_placement() != 0) {
    set_log_device_placement(from.log_device_placement());
  }
  if (from.has_graph_options()) {
    mutable_graph_options()->::tensorflow::GraphOptions::MergeFrom(from.graph_options());
  }
  if (from.operation_timeout_in_ms() != 0) {
    set_operation_timeout_in_ms(from.operation_timeout_in_ms());
  }
}

void ConfigProto::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.ConfigProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ConfigProto::CopyFrom(const ConfigProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.ConfigProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ConfigProto::IsInitialized() const {

  return true;
}

void ConfigProto::Swap(ConfigProto* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    ConfigProto temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void ConfigProto::UnsafeArenaSwap(ConfigProto* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void ConfigProto::InternalSwap(ConfigProto* other) {
  device_count_.Swap(&other->device_count_);
  std::swap(intra_op_parallelism_threads_, other->intra_op_parallelism_threads_);
  std::swap(inter_op_parallelism_threads_, other->inter_op_parallelism_threads_);
  std::swap(use_per_session_threads_, other->use_per_session_threads_);
  session_inter_op_thread_pool_.UnsafeArenaSwap(&other->session_inter_op_thread_pool_);
  std::swap(placement_period_, other->placement_period_);
  device_filters_.UnsafeArenaSwap(&other->device_filters_);
  std::swap(gpu_options_, other->gpu_options_);
  std::swap(allow_soft_placement_, other->allow_soft_placement_);
  std::swap(log_device_placement_, other->log_device_placement_);
  std::swap(graph_options_, other->graph_options_);
  std::swap(operation_timeout_in_ms_, other->operation_timeout_in_ms_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ConfigProto::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = ConfigProto_descriptor_;
  metadata.reflection = ConfigProto_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ConfigProto

// map<string, int32> device_count = 1;
int ConfigProto::device_count_size() const {
  return device_count_.size();
}
void ConfigProto::clear_device_count() {
  device_count_.Clear();
}
 const ::google::protobuf::Map< ::std::string, ::google::protobuf::int32 >&
ConfigProto::device_count() const {
  // @@protoc_insertion_point(field_map:tensorflow.ConfigProto.device_count)
  return device_count_.GetMap();
}
 ::google::protobuf::Map< ::std::string, ::google::protobuf::int32 >*
ConfigProto::mutable_device_count() {
  // @@protoc_insertion_point(field_mutable_map:tensorflow.ConfigProto.device_count)
  return device_count_.MutableMap();
}

// optional int32 intra_op_parallelism_threads = 2;
void ConfigProto::clear_intra_op_parallelism_threads() {
  intra_op_parallelism_threads_ = 0;
}
 ::google::protobuf::int32 ConfigProto::intra_op_parallelism_threads() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.intra_op_parallelism_threads)
  return intra_op_parallelism_threads_;
}
 void ConfigProto::set_intra_op_parallelism_threads(::google::protobuf::int32 value) {
  
  intra_op_parallelism_threads_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.intra_op_parallelism_threads)
}

// optional int32 inter_op_parallelism_threads = 5;
void ConfigProto::clear_inter_op_parallelism_threads() {
  inter_op_parallelism_threads_ = 0;
}
 ::google::protobuf::int32 ConfigProto::inter_op_parallelism_threads() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.inter_op_parallelism_threads)
  return inter_op_parallelism_threads_;
}
 void ConfigProto::set_inter_op_parallelism_threads(::google::protobuf::int32 value) {
  
  inter_op_parallelism_threads_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.inter_op_parallelism_threads)
}

// optional bool use_per_session_threads = 9;
void ConfigProto::clear_use_per_session_threads() {
  use_per_session_threads_ = false;
}
 bool ConfigProto::use_per_session_threads() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.use_per_session_threads)
  return use_per_session_threads_;
}
 void ConfigProto::set_use_per_session_threads(bool value) {
  
  use_per_session_threads_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.use_per_session_threads)
}

// repeated .tensorflow.ThreadPoolOptionProto session_inter_op_thread_pool = 12;
int ConfigProto::session_inter_op_thread_pool_size() const {
  return session_inter_op_thread_pool_.size();
}
void ConfigProto::clear_session_inter_op_thread_pool() {
  session_inter_op_thread_pool_.Clear();
}
const ::tensorflow::ThreadPoolOptionProto& ConfigProto::session_inter_op_thread_pool(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.session_inter_op_thread_pool)
  return session_inter_op_thread_pool_.Get(index);
}
::tensorflow::ThreadPoolOptionProto* ConfigProto::mutable_session_inter_op_thread_pool(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.ConfigProto.session_inter_op_thread_pool)
  return session_inter_op_thread_pool_.Mutable(index);
}
::tensorflow::ThreadPoolOptionProto* ConfigProto::add_session_inter_op_thread_pool() {
  // @@protoc_insertion_point(field_add:tensorflow.ConfigProto.session_inter_op_thread_pool)
  return session_inter_op_thread_pool_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::ThreadPoolOptionProto >*
ConfigProto::mutable_session_inter_op_thread_pool() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.ConfigProto.session_inter_op_thread_pool)
  return &session_inter_op_thread_pool_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::ThreadPoolOptionProto >&
ConfigProto::session_inter_op_thread_pool() const {
  // @@protoc_insertion_point(field_list:tensorflow.ConfigProto.session_inter_op_thread_pool)
  return session_inter_op_thread_pool_;
}

// optional int32 placement_period = 3;
void ConfigProto::clear_placement_period() {
  placement_period_ = 0;
}
 ::google::protobuf::int32 ConfigProto::placement_period() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.placement_period)
  return placement_period_;
}
 void ConfigProto::set_placement_period(::google::protobuf::int32 value) {
  
  placement_period_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.placement_period)
}

// repeated string device_filters = 4;
int ConfigProto::device_filters_size() const {
  return device_filters_.size();
}
void ConfigProto::clear_device_filters() {
  device_filters_.Clear();
}
 const ::std::string& ConfigProto::device_filters(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.device_filters)
  return device_filters_.Get(index);
}
 ::std::string* ConfigProto::mutable_device_filters(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.ConfigProto.device_filters)
  return device_filters_.Mutable(index);
}
 void ConfigProto::set_device_filters(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.device_filters)
  device_filters_.Mutable(index)->assign(value);
}
 void ConfigProto::set_device_filters(int index, const char* value) {
  device_filters_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:tensorflow.ConfigProto.device_filters)
}
 void ConfigProto::set_device_filters(int index, const char* value, size_t size) {
  device_filters_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:tensorflow.ConfigProto.device_filters)
}
 ::std::string* ConfigProto::add_device_filters() {
  // @@protoc_insertion_point(field_add_mutable:tensorflow.ConfigProto.device_filters)
  return device_filters_.Add();
}
 void ConfigProto::add_device_filters(const ::std::string& value) {
  device_filters_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:tensorflow.ConfigProto.device_filters)
}
 void ConfigProto::add_device_filters(const char* value) {
  device_filters_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:tensorflow.ConfigProto.device_filters)
}
 void ConfigProto::add_device_filters(const char* value, size_t size) {
  device_filters_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:tensorflow.ConfigProto.device_filters)
}
 const ::google::protobuf::RepeatedPtrField< ::std::string>&
ConfigProto::device_filters() const {
  // @@protoc_insertion_point(field_list:tensorflow.ConfigProto.device_filters)
  return device_filters_;
}
 ::google::protobuf::RepeatedPtrField< ::std::string>*
ConfigProto::mutable_device_filters() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.ConfigProto.device_filters)
  return &device_filters_;
}

// optional .tensorflow.GPUOptions gpu_options = 6;
bool ConfigProto::has_gpu_options() const {
  return !_is_default_instance_ && gpu_options_ != NULL;
}
void ConfigProto::clear_gpu_options() {
  if (GetArenaNoVirtual() == NULL && gpu_options_ != NULL) delete gpu_options_;
  gpu_options_ = NULL;
}
const ::tensorflow::GPUOptions& ConfigProto::gpu_options() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.gpu_options)
  return gpu_options_ != NULL ? *gpu_options_ : *default_instance_->gpu_options_;
}
::tensorflow::GPUOptions* ConfigProto::mutable_gpu_options() {
  
  if (gpu_options_ == NULL) {
    _slow_mutable_gpu_options();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.ConfigProto.gpu_options)
  return gpu_options_;
}
::tensorflow::GPUOptions* ConfigProto::release_gpu_options() {
  // @@protoc_insertion_point(field_release:tensorflow.ConfigProto.gpu_options)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_gpu_options();
  } else {
    ::tensorflow::GPUOptions* temp = gpu_options_;
    gpu_options_ = NULL;
    return temp;
  }
}
 void ConfigProto::set_allocated_gpu_options(::tensorflow::GPUOptions* gpu_options) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete gpu_options_;
  }
  if (gpu_options != NULL) {
    _slow_set_allocated_gpu_options(message_arena, &gpu_options);
  }
  gpu_options_ = gpu_options;
  if (gpu_options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.ConfigProto.gpu_options)
}

// optional bool allow_soft_placement = 7;
void ConfigProto::clear_allow_soft_placement() {
  allow_soft_placement_ = false;
}
 bool ConfigProto::allow_soft_placement() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.allow_soft_placement)
  return allow_soft_placement_;
}
 void ConfigProto::set_allow_soft_placement(bool value) {
  
  allow_soft_placement_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.allow_soft_placement)
}

// optional bool log_device_placement = 8;
void ConfigProto::clear_log_device_placement() {
  log_device_placement_ = false;
}
 bool ConfigProto::log_device_placement() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.log_device_placement)
  return log_device_placement_;
}
 void ConfigProto::set_log_device_placement(bool value) {
  
  log_device_placement_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.log_device_placement)
}

// optional .tensorflow.GraphOptions graph_options = 10;
bool ConfigProto::has_graph_options() const {
  return !_is_default_instance_ && graph_options_ != NULL;
}
void ConfigProto::clear_graph_options() {
  if (GetArenaNoVirtual() == NULL && graph_options_ != NULL) delete graph_options_;
  graph_options_ = NULL;
}
const ::tensorflow::GraphOptions& ConfigProto::graph_options() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.graph_options)
  return graph_options_ != NULL ? *graph_options_ : *default_instance_->graph_options_;
}
::tensorflow::GraphOptions* ConfigProto::mutable_graph_options() {
  
  if (graph_options_ == NULL) {
    _slow_mutable_graph_options();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.ConfigProto.graph_options)
  return graph_options_;
}
::tensorflow::GraphOptions* ConfigProto::release_graph_options() {
  // @@protoc_insertion_point(field_release:tensorflow.ConfigProto.graph_options)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_graph_options();
  } else {
    ::tensorflow::GraphOptions* temp = graph_options_;
    graph_options_ = NULL;
    return temp;
  }
}
 void ConfigProto::set_allocated_graph_options(::tensorflow::GraphOptions* graph_options) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete graph_options_;
  }
  if (graph_options != NULL) {
    _slow_set_allocated_graph_options(message_arena, &graph_options);
  }
  graph_options_ = graph_options;
  if (graph_options) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.ConfigProto.graph_options)
}

// optional int64 operation_timeout_in_ms = 11;
void ConfigProto::clear_operation_timeout_in_ms() {
  operation_timeout_in_ms_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 ConfigProto::operation_timeout_in_ms() const {
  // @@protoc_insertion_point(field_get:tensorflow.ConfigProto.operation_timeout_in_ms)
  return operation_timeout_in_ms_;
}
 void ConfigProto::set_operation_timeout_in_ms(::google::protobuf::int64 value) {
  
  operation_timeout_in_ms_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.ConfigProto.operation_timeout_in_ms)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int DebugTensorWatch::kNodeNameFieldNumber;
const int DebugTensorWatch::kOutputSlotFieldNumber;
const int DebugTensorWatch::kDebugOpsFieldNumber;
const int DebugTensorWatch::kDebugUrlsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

DebugTensorWatch::DebugTensorWatch()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.DebugTensorWatch)
}

DebugTensorWatch::DebugTensorWatch(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena),
  debug_ops_(arena),
  debug_urls_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.DebugTensorWatch)
}

void DebugTensorWatch::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

DebugTensorWatch::DebugTensorWatch(const DebugTensorWatch& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.DebugTensorWatch)
}

void DebugTensorWatch::SharedCtor() {
    _is_default_instance_ = false;
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  node_name_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  output_slot_ = 0;
}

DebugTensorWatch::~DebugTensorWatch() {
  // @@protoc_insertion_point(destructor:tensorflow.DebugTensorWatch)
  SharedDtor();
}

void DebugTensorWatch::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  node_name_.Destroy(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
  if (this != default_instance_) {
  }
}

void DebugTensorWatch::ArenaDtor(void* object) {
  DebugTensorWatch* _this = reinterpret_cast< DebugTensorWatch* >(object);
  (void)_this;
}
void DebugTensorWatch::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void DebugTensorWatch::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* DebugTensorWatch::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return DebugTensorWatch_descriptor_;
}

const DebugTensorWatch& DebugTensorWatch::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto();
  return *default_instance_;
}

DebugTensorWatch* DebugTensorWatch::default_instance_ = NULL;

DebugTensorWatch* DebugTensorWatch::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<DebugTensorWatch>(arena);
}

void DebugTensorWatch::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.DebugTensorWatch)
  node_name_.ClearToEmpty(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
  output_slot_ = 0;
  debug_ops_.Clear();
  debug_urls_.Clear();
}

bool DebugTensorWatch::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.DebugTensorWatch)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional string node_name = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_node_name()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->node_name().data(), this->node_name().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.DebugTensorWatch.node_name"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_output_slot;
        break;
      }

      // optional int32 output_slot = 2;
      case 2: {
        if (tag == 16) {
         parse_output_slot:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &output_slot_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(26)) goto parse_debug_ops;
        break;
      }

      // repeated string debug_ops = 3;
      case 3: {
        if (tag == 26) {
         parse_debug_ops:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->add_debug_ops()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->debug_ops(this->debug_ops_size() - 1).data(),
            this->debug_ops(this->debug_ops_size() - 1).length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.DebugTensorWatch.debug_ops"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(26)) goto parse_debug_ops;
        if (input->ExpectTag(34)) goto parse_debug_urls;
        break;
      }

      // repeated string debug_urls = 4;
      case 4: {
        if (tag == 34) {
         parse_debug_urls:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->add_debug_urls()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->debug_urls(this->debug_urls_size() - 1).data(),
            this->debug_urls(this->debug_urls_size() - 1).length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.DebugTensorWatch.debug_urls"));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_debug_urls;
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.DebugTensorWatch)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.DebugTensorWatch)
  return false;
#undef DO_
}

void DebugTensorWatch::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.DebugTensorWatch)
  // optional string node_name = 1;
  if (this->node_name().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->node_name().data(), this->node_name().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.DebugTensorWatch.node_name");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->node_name(), output);
  }

  // optional int32 output_slot = 2;
  if (this->output_slot() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(2, this->output_slot(), output);
  }

  // repeated string debug_ops = 3;
  for (int i = 0; i < this->debug_ops_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->debug_ops(i).data(), this->debug_ops(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.DebugTensorWatch.debug_ops");
    ::google::protobuf::internal::WireFormatLite::WriteString(
      3, this->debug_ops(i), output);
  }

  // repeated string debug_urls = 4;
  for (int i = 0; i < this->debug_urls_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->debug_urls(i).data(), this->debug_urls(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.DebugTensorWatch.debug_urls");
    ::google::protobuf::internal::WireFormatLite::WriteString(
      4, this->debug_urls(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.DebugTensorWatch)
}

::google::protobuf::uint8* DebugTensorWatch::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.DebugTensorWatch)
  // optional string node_name = 1;
  if (this->node_name().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->node_name().data(), this->node_name().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.DebugTensorWatch.node_name");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->node_name(), target);
  }

  // optional int32 output_slot = 2;
  if (this->output_slot() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(2, this->output_slot(), target);
  }

  // repeated string debug_ops = 3;
  for (int i = 0; i < this->debug_ops_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->debug_ops(i).data(), this->debug_ops(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.DebugTensorWatch.debug_ops");
    target = ::google::protobuf::internal::WireFormatLite::
      WriteStringToArray(3, this->debug_ops(i), target);
  }

  // repeated string debug_urls = 4;
  for (int i = 0; i < this->debug_urls_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->debug_urls(i).data(), this->debug_urls(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.DebugTensorWatch.debug_urls");
    target = ::google::protobuf::internal::WireFormatLite::
      WriteStringToArray(4, this->debug_urls(i), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.DebugTensorWatch)
  return target;
}

int DebugTensorWatch::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.DebugTensorWatch)
  int total_size = 0;

  // optional string node_name = 1;
  if (this->node_name().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->node_name());
  }

  // optional int32 output_slot = 2;
  if (this->output_slot() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->output_slot());
  }

  // repeated string debug_ops = 3;
  total_size += 1 * this->debug_ops_size();
  for (int i = 0; i < this->debug_ops_size(); i++) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
      this->debug_ops(i));
  }

  // repeated string debug_urls = 4;
  total_size += 1 * this->debug_urls_size();
  for (int i = 0; i < this->debug_urls_size(); i++) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
      this->debug_urls(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void DebugTensorWatch::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.DebugTensorWatch)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const DebugTensorWatch* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const DebugTensorWatch>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.DebugTensorWatch)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.DebugTensorWatch)
    MergeFrom(*source);
  }
}

void DebugTensorWatch::MergeFrom(const DebugTensorWatch& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.DebugTensorWatch)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  debug_ops_.MergeFrom(from.debug_ops_);
  debug_urls_.MergeFrom(from.debug_urls_);
  if (from.node_name().size() > 0) {
    set_node_name(from.node_name());
  }
  if (from.output_slot() != 0) {
    set_output_slot(from.output_slot());
  }
}

void DebugTensorWatch::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.DebugTensorWatch)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void DebugTensorWatch::CopyFrom(const DebugTensorWatch& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.DebugTensorWatch)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool DebugTensorWatch::IsInitialized() const {

  return true;
}

void DebugTensorWatch::Swap(DebugTensorWatch* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    DebugTensorWatch temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void DebugTensorWatch::UnsafeArenaSwap(DebugTensorWatch* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void DebugTensorWatch::InternalSwap(DebugTensorWatch* other) {
  node_name_.Swap(&other->node_name_);
  std::swap(output_slot_, other->output_slot_);
  debug_ops_.UnsafeArenaSwap(&other->debug_ops_);
  debug_urls_.UnsafeArenaSwap(&other->debug_urls_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata DebugTensorWatch::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = DebugTensorWatch_descriptor_;
  metadata.reflection = DebugTensorWatch_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// DebugTensorWatch

// optional string node_name = 1;
void DebugTensorWatch::clear_node_name() {
  node_name_.ClearToEmpty(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
 const ::std::string& DebugTensorWatch::node_name() const {
  // @@protoc_insertion_point(field_get:tensorflow.DebugTensorWatch.node_name)
  return node_name_.Get(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void DebugTensorWatch::set_node_name(const ::std::string& value) {
  
  node_name_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value, GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set:tensorflow.DebugTensorWatch.node_name)
}
 void DebugTensorWatch::set_node_name(const char* value) {
  
  node_name_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value),
              GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_char:tensorflow.DebugTensorWatch.node_name)
}
 void DebugTensorWatch::set_node_name(const char* value,
    size_t size) {
  
  node_name_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size), GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_pointer:tensorflow.DebugTensorWatch.node_name)
}
 ::std::string* DebugTensorWatch::mutable_node_name() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.DebugTensorWatch.node_name)
  return node_name_.Mutable(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
 ::std::string* DebugTensorWatch::release_node_name() {
  // @@protoc_insertion_point(field_release:tensorflow.DebugTensorWatch.node_name)
  
  return node_name_.Release(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
 ::std::string* DebugTensorWatch::unsafe_arena_release_node_name() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.DebugTensorWatch.node_name)
  GOOGLE_DCHECK(GetArenaNoVirtual() != NULL);
  
  return node_name_.UnsafeArenaRelease(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      GetArenaNoVirtual());
}
 void DebugTensorWatch::set_allocated_node_name(::std::string* node_name) {
  if (node_name != NULL) {
    
  } else {
    
  }
  node_name_.SetAllocated(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), node_name,
      GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_allocated:tensorflow.DebugTensorWatch.node_name)
}
 void DebugTensorWatch::unsafe_arena_set_allocated_node_name(
    ::std::string* node_name) {
  GOOGLE_DCHECK(GetArenaNoVirtual() != NULL);
  if (node_name != NULL) {
    
  } else {
    
  }
  node_name_.UnsafeArenaSetAllocated(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      node_name, GetArenaNoVirtual());
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.DebugTensorWatch.node_name)
}

// optional int32 output_slot = 2;
void DebugTensorWatch::clear_output_slot() {
  output_slot_ = 0;
}
 ::google::protobuf::int32 DebugTensorWatch::output_slot() const {
  // @@protoc_insertion_point(field_get:tensorflow.DebugTensorWatch.output_slot)
  return output_slot_;
}
 void DebugTensorWatch::set_output_slot(::google::protobuf::int32 value) {
  
  output_slot_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.DebugTensorWatch.output_slot)
}

// repeated string debug_ops = 3;
int DebugTensorWatch::debug_ops_size() const {
  return debug_ops_.size();
}
void DebugTensorWatch::clear_debug_ops() {
  debug_ops_.Clear();
}
 const ::std::string& DebugTensorWatch::debug_ops(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.DebugTensorWatch.debug_ops)
  return debug_ops_.Get(index);
}
 ::std::string* DebugTensorWatch::mutable_debug_ops(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.DebugTensorWatch.debug_ops)
  return debug_ops_.Mutable(index);
}
 void DebugTensorWatch::set_debug_ops(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:tensorflow.DebugTensorWatch.debug_ops)
  debug_ops_.Mutable(index)->assign(value);
}
 void DebugTensorWatch::set_debug_ops(int index, const char* value) {
  debug_ops_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:tensorflow.DebugTensorWatch.debug_ops)
}
 void DebugTensorWatch::set_debug_ops(int index, const char* value, size_t size) {
  debug_ops_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:tensorflow.DebugTensorWatch.debug_ops)
}
 ::std::string* DebugTensorWatch::add_debug_ops() {
  // @@protoc_insertion_point(field_add_mutable:tensorflow.DebugTensorWatch.debug_ops)
  return debug_ops_.Add();
}
 void DebugTensorWatch::add_debug_ops(const ::std::string& value) {
  debug_ops_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:tensorflow.DebugTensorWatch.debug_ops)
}
 void DebugTensorWatch::add_debug_ops(const char* value) {
  debug_ops_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:tensorflow.DebugTensorWatch.debug_ops)
}
 void DebugTensorWatch::add_debug_ops(const char* value, size_t size) {
  debug_ops_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:tensorflow.DebugTensorWatch.debug_ops)
}
 const ::google::protobuf::RepeatedPtrField< ::std::string>&
DebugTensorWatch::debug_ops() const {
  // @@protoc_insertion_point(field_list:tensorflow.DebugTensorWatch.debug_ops)
  return debug_ops_;
}
 ::google::protobuf::RepeatedPtrField< ::std::string>*
DebugTensorWatch::mutable_debug_ops() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.DebugTensorWatch.debug_ops)
  return &debug_ops_;
}

// repeated string debug_urls = 4;
int DebugTensorWatch::debug_urls_size() const {
  return debug_urls_.size();
}
void DebugTensorWatch::clear_debug_urls() {
  debug_urls_.Clear();
}
 const ::std::string& DebugTensorWatch::debug_urls(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.DebugTensorWatch.debug_urls)
  return debug_urls_.Get(index);
}
 ::std::string* DebugTensorWatch::mutable_debug_urls(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.DebugTensorWatch.debug_urls)
  return debug_urls_.Mutable(index);
}
 void DebugTensorWatch::set_debug_urls(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:tensorflow.DebugTensorWatch.debug_urls)
  debug_urls_.Mutable(index)->assign(value);
}
 void DebugTensorWatch::set_debug_urls(int index, const char* value) {
  debug_urls_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:tensorflow.DebugTensorWatch.debug_urls)
}
 void DebugTensorWatch::set_debug_urls(int index, const char* value, size_t size) {
  debug_urls_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:tensorflow.DebugTensorWatch.debug_urls)
}
 ::std::string* DebugTensorWatch::add_debug_urls() {
  // @@protoc_insertion_point(field_add_mutable:tensorflow.DebugTensorWatch.debug_urls)
  return debug_urls_.Add();
}
 void DebugTensorWatch::add_debug_urls(const ::std::string& value) {
  debug_urls_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:tensorflow.DebugTensorWatch.debug_urls)
}
 void DebugTensorWatch::add_debug_urls(const char* value) {
  debug_urls_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:tensorflow.DebugTensorWatch.debug_urls)
}
 void DebugTensorWatch::add_debug_urls(const char* value, size_t size) {
  debug_urls_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:tensorflow.DebugTensorWatch.debug_urls)
}
 const ::google::protobuf::RepeatedPtrField< ::std::string>&
DebugTensorWatch::debug_urls() const {
  // @@protoc_insertion_point(field_list:tensorflow.DebugTensorWatch.debug_urls)
  return debug_urls_;
}
 ::google::protobuf::RepeatedPtrField< ::std::string>*
DebugTensorWatch::mutable_debug_urls() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.DebugTensorWatch.debug_urls)
  return &debug_urls_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

const ::google::protobuf::EnumDescriptor* RunOptions_TraceLevel_descriptor() {
  protobuf_AssignDescriptorsOnce();
  return RunOptions_TraceLevel_descriptor_;
}
bool RunOptions_TraceLevel_IsValid(int value) {
  switch(value) {
    case 0:
    case 1:
    case 2:
    case 3:
      return true;
    default:
      return false;
  }
}

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const RunOptions_TraceLevel RunOptions::NO_TRACE;
const RunOptions_TraceLevel RunOptions::SOFTWARE_TRACE;
const RunOptions_TraceLevel RunOptions::HARDWARE_TRACE;
const RunOptions_TraceLevel RunOptions::FULL_TRACE;
const RunOptions_TraceLevel RunOptions::TraceLevel_MIN;
const RunOptions_TraceLevel RunOptions::TraceLevel_MAX;
const int RunOptions::TraceLevel_ARRAYSIZE;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RunOptions::kTraceLevelFieldNumber;
const int RunOptions::kTimeoutInMsFieldNumber;
const int RunOptions::kInterOpThreadPoolFieldNumber;
const int RunOptions::kDebugTensorWatchOptsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RunOptions::RunOptions()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.RunOptions)
}

RunOptions::RunOptions(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena),
  debug_tensor_watch_opts_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.RunOptions)
}

void RunOptions::InitAsDefaultInstance() {
  _is_default_instance_ = true;
}

RunOptions::RunOptions(const RunOptions& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.RunOptions)
}

void RunOptions::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  trace_level_ = 0;
  timeout_in_ms_ = GOOGLE_LONGLONG(0);
  inter_op_thread_pool_ = 0;
}

RunOptions::~RunOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.RunOptions)
  SharedDtor();
}

void RunOptions::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  if (this != default_instance_) {
  }
}

void RunOptions::ArenaDtor(void* object) {
  RunOptions* _this = reinterpret_cast< RunOptions* >(object);
  (void)_this;
}
void RunOptions::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void RunOptions::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RunOptions::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return RunOptions_descriptor_;
}

const RunOptions& RunOptions::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto();
  return *default_instance_;
}

RunOptions* RunOptions::default_instance_ = NULL;

RunOptions* RunOptions::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<RunOptions>(arena);
}

void RunOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RunOptions)
#if defined(__clang__)
#define ZR_HELPER_(f) \
  _Pragma("clang diagnostic push") \
  _Pragma("clang diagnostic ignored \"-Winvalid-offsetof\"") \
  __builtin_offsetof(RunOptions, f) \
  _Pragma("clang diagnostic pop")
#else
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<RunOptions*>(16)->f)
#endif

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  ZR_(timeout_in_ms_, inter_op_thread_pool_);

#undef ZR_HELPER_
#undef ZR_

  debug_tensor_watch_opts_.Clear();
}

bool RunOptions::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.RunOptions)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.RunOptions.TraceLevel trace_level = 1;
      case 1: {
        if (tag == 8) {
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          set_trace_level(static_cast< ::tensorflow::RunOptions_TraceLevel >(value));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_timeout_in_ms;
        break;
      }

      // optional int64 timeout_in_ms = 2;
      case 2: {
        if (tag == 16) {
         parse_timeout_in_ms:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, &timeout_in_ms_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_inter_op_thread_pool;
        break;
      }

      // optional int32 inter_op_thread_pool = 3;
      case 3: {
        if (tag == 24) {
         parse_inter_op_thread_pool:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &inter_op_thread_pool_)));

        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_debug_tensor_watch_opts;
        break;
      }

      // repeated .tensorflow.DebugTensorWatch debug_tensor_watch_opts = 4;
      case 4: {
        if (tag == 34) {
         parse_debug_tensor_watch_opts:
          DO_(input->IncrementRecursionDepth());
         parse_loop_debug_tensor_watch_opts:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_debug_tensor_watch_opts()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_loop_debug_tensor_watch_opts;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.RunOptions)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.RunOptions)
  return false;
#undef DO_
}

void RunOptions::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.RunOptions)
  // optional .tensorflow.RunOptions.TraceLevel trace_level = 1;
  if (this->trace_level() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      1, this->trace_level(), output);
  }

  // optional int64 timeout_in_ms = 2;
  if (this->timeout_in_ms() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64(2, this->timeout_in_ms(), output);
  }

  // optional int32 inter_op_thread_pool = 3;
  if (this->inter_op_thread_pool() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(3, this->inter_op_thread_pool(), output);
  }

  // repeated .tensorflow.DebugTensorWatch debug_tensor_watch_opts = 4;
  for (unsigned int i = 0, n = this->debug_tensor_watch_opts_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      4, this->debug_tensor_watch_opts(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.RunOptions)
}

::google::protobuf::uint8* RunOptions::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RunOptions)
  // optional .tensorflow.RunOptions.TraceLevel trace_level = 1;
  if (this->trace_level() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      1, this->trace_level(), target);
  }

  // optional int64 timeout_in_ms = 2;
  if (this->timeout_in_ms() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt64ToArray(2, this->timeout_in_ms(), target);
  }

  // optional int32 inter_op_thread_pool = 3;
  if (this->inter_op_thread_pool() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(3, this->inter_op_thread_pool(), target);
  }

  // repeated .tensorflow.DebugTensorWatch debug_tensor_watch_opts = 4;
  for (unsigned int i = 0, n = this->debug_tensor_watch_opts_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        4, this->debug_tensor_watch_opts(i), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RunOptions)
  return target;
}

int RunOptions::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.RunOptions)
  int total_size = 0;

  // optional .tensorflow.RunOptions.TraceLevel trace_level = 1;
  if (this->trace_level() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::EnumSize(this->trace_level());
  }

  // optional int64 timeout_in_ms = 2;
  if (this->timeout_in_ms() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int64Size(
        this->timeout_in_ms());
  }

  // optional int32 inter_op_thread_pool = 3;
  if (this->inter_op_thread_pool() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->inter_op_thread_pool());
  }

  // repeated .tensorflow.DebugTensorWatch debug_tensor_watch_opts = 4;
  total_size += 1 * this->debug_tensor_watch_opts_size();
  for (int i = 0; i < this->debug_tensor_watch_opts_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->debug_tensor_watch_opts(i));
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RunOptions::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.RunOptions)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const RunOptions* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const RunOptions>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.RunOptions)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.RunOptions)
    MergeFrom(*source);
  }
}

void RunOptions::MergeFrom(const RunOptions& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RunOptions)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  debug_tensor_watch_opts_.MergeFrom(from.debug_tensor_watch_opts_);
  if (from.trace_level() != 0) {
    set_trace_level(from.trace_level());
  }
  if (from.timeout_in_ms() != 0) {
    set_timeout_in_ms(from.timeout_in_ms());
  }
  if (from.inter_op_thread_pool() != 0) {
    set_inter_op_thread_pool(from.inter_op_thread_pool());
  }
}

void RunOptions::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.RunOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RunOptions::CopyFrom(const RunOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RunOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RunOptions::IsInitialized() const {

  return true;
}

void RunOptions::Swap(RunOptions* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    RunOptions temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void RunOptions::UnsafeArenaSwap(RunOptions* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void RunOptions::InternalSwap(RunOptions* other) {
  std::swap(trace_level_, other->trace_level_);
  std::swap(timeout_in_ms_, other->timeout_in_ms_);
  std::swap(inter_op_thread_pool_, other->inter_op_thread_pool_);
  debug_tensor_watch_opts_.UnsafeArenaSwap(&other->debug_tensor_watch_opts_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RunOptions::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = RunOptions_descriptor_;
  metadata.reflection = RunOptions_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RunOptions

// optional .tensorflow.RunOptions.TraceLevel trace_level = 1;
void RunOptions::clear_trace_level() {
  trace_level_ = 0;
}
 ::tensorflow::RunOptions_TraceLevel RunOptions::trace_level() const {
  // @@protoc_insertion_point(field_get:tensorflow.RunOptions.trace_level)
  return static_cast< ::tensorflow::RunOptions_TraceLevel >(trace_level_);
}
 void RunOptions::set_trace_level(::tensorflow::RunOptions_TraceLevel value) {
  
  trace_level_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.RunOptions.trace_level)
}

// optional int64 timeout_in_ms = 2;
void RunOptions::clear_timeout_in_ms() {
  timeout_in_ms_ = GOOGLE_LONGLONG(0);
}
 ::google::protobuf::int64 RunOptions::timeout_in_ms() const {
  // @@protoc_insertion_point(field_get:tensorflow.RunOptions.timeout_in_ms)
  return timeout_in_ms_;
}
 void RunOptions::set_timeout_in_ms(::google::protobuf::int64 value) {
  
  timeout_in_ms_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.RunOptions.timeout_in_ms)
}

// optional int32 inter_op_thread_pool = 3;
void RunOptions::clear_inter_op_thread_pool() {
  inter_op_thread_pool_ = 0;
}
 ::google::protobuf::int32 RunOptions::inter_op_thread_pool() const {
  // @@protoc_insertion_point(field_get:tensorflow.RunOptions.inter_op_thread_pool)
  return inter_op_thread_pool_;
}
 void RunOptions::set_inter_op_thread_pool(::google::protobuf::int32 value) {
  
  inter_op_thread_pool_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.RunOptions.inter_op_thread_pool)
}

// repeated .tensorflow.DebugTensorWatch debug_tensor_watch_opts = 4;
int RunOptions::debug_tensor_watch_opts_size() const {
  return debug_tensor_watch_opts_.size();
}
void RunOptions::clear_debug_tensor_watch_opts() {
  debug_tensor_watch_opts_.Clear();
}
const ::tensorflow::DebugTensorWatch& RunOptions::debug_tensor_watch_opts(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.RunOptions.debug_tensor_watch_opts)
  return debug_tensor_watch_opts_.Get(index);
}
::tensorflow::DebugTensorWatch* RunOptions::mutable_debug_tensor_watch_opts(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.RunOptions.debug_tensor_watch_opts)
  return debug_tensor_watch_opts_.Mutable(index);
}
::tensorflow::DebugTensorWatch* RunOptions::add_debug_tensor_watch_opts() {
  // @@protoc_insertion_point(field_add:tensorflow.RunOptions.debug_tensor_watch_opts)
  return debug_tensor_watch_opts_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::DebugTensorWatch >*
RunOptions::mutable_debug_tensor_watch_opts() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.RunOptions.debug_tensor_watch_opts)
  return &debug_tensor_watch_opts_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::DebugTensorWatch >&
RunOptions::debug_tensor_watch_opts() const {
  // @@protoc_insertion_point(field_list:tensorflow.RunOptions.debug_tensor_watch_opts)
  return debug_tensor_watch_opts_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

void RunMetadata::_slow_mutable_step_stats() {
  step_stats_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::StepStats >(
      GetArenaNoVirtual());
}
::tensorflow::StepStats* RunMetadata::_slow_release_step_stats() {
  if (step_stats_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::StepStats* temp = new ::tensorflow::StepStats;
    temp->MergeFrom(*step_stats_);
    step_stats_ = NULL;
    return temp;
  }
}
::tensorflow::StepStats* RunMetadata::unsafe_arena_release_step_stats() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.RunMetadata.step_stats)
  
  ::tensorflow::StepStats* temp = step_stats_;
  step_stats_ = NULL;
  return temp;
}
void RunMetadata::_slow_set_allocated_step_stats(
    ::google::protobuf::Arena* message_arena, ::tensorflow::StepStats** step_stats) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*step_stats) == NULL) {
      message_arena->Own(*step_stats);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*step_stats)) {
      ::tensorflow::StepStats* new_step_stats = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::StepStats >(
            message_arena);
      new_step_stats->CopyFrom(**step_stats);
      *step_stats = new_step_stats;
    }
}
void RunMetadata::unsafe_arena_set_allocated_step_stats(
    ::tensorflow::StepStats* step_stats) {
  if (GetArenaNoVirtual() == NULL) {
    delete step_stats_;
  }
  step_stats_ = step_stats;
  if (step_stats) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.RunMetadata.step_stats)
}
void RunMetadata::_slow_mutable_cost_graph() {
  cost_graph_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::CostGraphDef >(
      GetArenaNoVirtual());
}
::tensorflow::CostGraphDef* RunMetadata::_slow_release_cost_graph() {
  if (cost_graph_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::CostGraphDef* temp = new ::tensorflow::CostGraphDef;
    temp->MergeFrom(*cost_graph_);
    cost_graph_ = NULL;
    return temp;
  }
}
::tensorflow::CostGraphDef* RunMetadata::unsafe_arena_release_cost_graph() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.RunMetadata.cost_graph)
  
  ::tensorflow::CostGraphDef* temp = cost_graph_;
  cost_graph_ = NULL;
  return temp;
}
void RunMetadata::_slow_set_allocated_cost_graph(
    ::google::protobuf::Arena* message_arena, ::tensorflow::CostGraphDef** cost_graph) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*cost_graph) == NULL) {
      message_arena->Own(*cost_graph);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*cost_graph)) {
      ::tensorflow::CostGraphDef* new_cost_graph = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::CostGraphDef >(
            message_arena);
      new_cost_graph->CopyFrom(**cost_graph);
      *cost_graph = new_cost_graph;
    }
}
void RunMetadata::unsafe_arena_set_allocated_cost_graph(
    ::tensorflow::CostGraphDef* cost_graph) {
  if (GetArenaNoVirtual() == NULL) {
    delete cost_graph_;
  }
  cost_graph_ = cost_graph;
  if (cost_graph) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.RunMetadata.cost_graph)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RunMetadata::kStepStatsFieldNumber;
const int RunMetadata::kCostGraphFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RunMetadata::RunMetadata()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.RunMetadata)
}

RunMetadata::RunMetadata(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.RunMetadata)
}

void RunMetadata::InitAsDefaultInstance() {
  _is_default_instance_ = true;
  step_stats_ = const_cast< ::tensorflow::StepStats*>(&::tensorflow::StepStats::default_instance());
  cost_graph_ = const_cast< ::tensorflow::CostGraphDef*>(&::tensorflow::CostGraphDef::default_instance());
}

RunMetadata::RunMetadata(const RunMetadata& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.RunMetadata)
}

void RunMetadata::SharedCtor() {
    _is_default_instance_ = false;
  _cached_size_ = 0;
  step_stats_ = NULL;
  cost_graph_ = NULL;
}

RunMetadata::~RunMetadata() {
  // @@protoc_insertion_point(destructor:tensorflow.RunMetadata)
  SharedDtor();
}

void RunMetadata::SharedDtor() {
  if (GetArenaNoVirtual() != NULL) {
    return;
  }

  if (this != default_instance_) {
    delete step_stats_;
    delete cost_graph_;
  }
}

void RunMetadata::ArenaDtor(void* object) {
  RunMetadata* _this = reinterpret_cast< RunMetadata* >(object);
  (void)_this;
}
void RunMetadata::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void RunMetadata::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RunMetadata::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return RunMetadata_descriptor_;
}

const RunMetadata& RunMetadata::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto();
  return *default_instance_;
}

RunMetadata* RunMetadata::default_instance_ = NULL;

RunMetadata* RunMetadata::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<RunMetadata>(arena);
}

void RunMetadata::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RunMetadata)
  if (GetArenaNoVirtual() == NULL && step_stats_ != NULL) delete step_stats_;
  step_stats_ = NULL;
  if (GetArenaNoVirtual() == NULL && cost_graph_ != NULL) delete cost_graph_;
  cost_graph_ = NULL;
}

bool RunMetadata::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.RunMetadata)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.StepStats step_stats = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_step_stats()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_cost_graph;
        break;
      }

      // optional .tensorflow.CostGraphDef cost_graph = 2;
      case 2: {
        if (tag == 18) {
         parse_cost_graph:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_cost_graph()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.RunMetadata)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.RunMetadata)
  return false;
#undef DO_
}

void RunMetadata::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.RunMetadata)
  // optional .tensorflow.StepStats step_stats = 1;
  if (this->has_step_stats()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->step_stats_, output);
  }

  // optional .tensorflow.CostGraphDef cost_graph = 2;
  if (this->has_cost_graph()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->cost_graph_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.RunMetadata)
}

::google::protobuf::uint8* RunMetadata::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RunMetadata)
  // optional .tensorflow.StepStats step_stats = 1;
  if (this->has_step_stats()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        1, *this->step_stats_, target);
  }

  // optional .tensorflow.CostGraphDef cost_graph = 2;
  if (this->has_cost_graph()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        2, *this->cost_graph_, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RunMetadata)
  return target;
}

int RunMetadata::ByteSize() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.RunMetadata)
  int total_size = 0;

  // optional .tensorflow.StepStats step_stats = 1;
  if (this->has_step_stats()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->step_stats_);
  }

  // optional .tensorflow.CostGraphDef cost_graph = 2;
  if (this->has_cost_graph()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->cost_graph_);
  }

  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RunMetadata::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.RunMetadata)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const RunMetadata* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const RunMetadata>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.RunMetadata)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.RunMetadata)
    MergeFrom(*source);
  }
}

void RunMetadata::MergeFrom(const RunMetadata& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RunMetadata)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from.has_step_stats()) {
    mutable_step_stats()->::tensorflow::StepStats::MergeFrom(from.step_stats());
  }
  if (from.has_cost_graph()) {
    mutable_cost_graph()->::tensorflow::CostGraphDef::MergeFrom(from.cost_graph());
  }
}

void RunMetadata::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.RunMetadata)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RunMetadata::CopyFrom(const RunMetadata& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RunMetadata)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RunMetadata::IsInitialized() const {

  return true;
}

void RunMetadata::Swap(RunMetadata* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    RunMetadata temp;
    temp.MergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void RunMetadata::UnsafeArenaSwap(RunMetadata* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void RunMetadata::InternalSwap(RunMetadata* other) {
  std::swap(step_stats_, other->step_stats_);
  std::swap(cost_graph_, other->cost_graph_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RunMetadata::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = RunMetadata_descriptor_;
  metadata.reflection = RunMetadata_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RunMetadata

// optional .tensorflow.StepStats step_stats = 1;
bool RunMetadata::has_step_stats() const {
  return !_is_default_instance_ && step_stats_ != NULL;
}
void RunMetadata::clear_step_stats() {
  if (GetArenaNoVirtual() == NULL && step_stats_ != NULL) delete step_stats_;
  step_stats_ = NULL;
}
const ::tensorflow::StepStats& RunMetadata::step_stats() const {
  // @@protoc_insertion_point(field_get:tensorflow.RunMetadata.step_stats)
  return step_stats_ != NULL ? *step_stats_ : *default_instance_->step_stats_;
}
::tensorflow::StepStats* RunMetadata::mutable_step_stats() {
  
  if (step_stats_ == NULL) {
    _slow_mutable_step_stats();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.RunMetadata.step_stats)
  return step_stats_;
}
::tensorflow::StepStats* RunMetadata::release_step_stats() {
  // @@protoc_insertion_point(field_release:tensorflow.RunMetadata.step_stats)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_step_stats();
  } else {
    ::tensorflow::StepStats* temp = step_stats_;
    step_stats_ = NULL;
    return temp;
  }
}
 void RunMetadata::set_allocated_step_stats(::tensorflow::StepStats* step_stats) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete step_stats_;
  }
  if (step_stats != NULL) {
    _slow_set_allocated_step_stats(message_arena, &step_stats);
  }
  step_stats_ = step_stats;
  if (step_stats) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.RunMetadata.step_stats)
}

// optional .tensorflow.CostGraphDef cost_graph = 2;
bool RunMetadata::has_cost_graph() const {
  return !_is_default_instance_ && cost_graph_ != NULL;
}
void RunMetadata::clear_cost_graph() {
  if (GetArenaNoVirtual() == NULL && cost_graph_ != NULL) delete cost_graph_;
  cost_graph_ = NULL;
}
const ::tensorflow::CostGraphDef& RunMetadata::cost_graph() const {
  // @@protoc_insertion_point(field_get:tensorflow.RunMetadata.cost_graph)
  return cost_graph_ != NULL ? *cost_graph_ : *default_instance_->cost_graph_;
}
::tensorflow::CostGraphDef* RunMetadata::mutable_cost_graph() {
  
  if (cost_graph_ == NULL) {
    _slow_mutable_cost_graph();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.RunMetadata.cost_graph)
  return cost_graph_;
}
::tensorflow::CostGraphDef* RunMetadata::release_cost_graph() {
  // @@protoc_insertion_point(field_release:tensorflow.RunMetadata.cost_graph)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_cost_graph();
  } else {
    ::tensorflow::CostGraphDef* temp = cost_graph_;
    cost_graph_ = NULL;
    return temp;
  }
}
 void RunMetadata::set_allocated_cost_graph(::tensorflow::CostGraphDef* cost_graph) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete cost_graph_;
  }
  if (cost_graph != NULL) {
    _slow_set_allocated_cost_graph(message_arena, &cost_graph);
  }
  cost_graph_ = cost_graph;
  if (cost_graph) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.RunMetadata.cost_graph)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
